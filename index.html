<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Reporte de Noticias - Inteligencia Artificial</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        .image-container {
            max-width: 500px;
            max-height: 500px;
            overflow: hidden;
            border: 2px solid #ccc;
            border-radius: 10px;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
            position: relative;
            margin: 0 auto;
        }

        .image-container img {
            width: 100%;
            height: auto;
            cursor: pointer;
            object-fit: cover;
        }

        /* Popup */
        .popup-overlay {
            display: none;
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0, 0, 0, 0.8);
            justify-content: center;
            align-items: center;
            z-index: 1000;
        }

        .popup-overlay img {
            max-width: 100%;
            max-height: 100%;
            cursor: grab;
            transition: transform 0.3s;
        }

        .popup-overlay.show {
            display: flex;
        }

        /* Botón de cierre */
        .close-btn {
            position: absolute;
            top: 20px;
            right: 20px;
            background: rgba(255, 255, 255, 0.8);
            border: none;
            font-size: 18px;
            font-weight: bold;
            cursor: pointer;
            padding: 5px 10px;
            border-radius: 5px;
            z-index: 1100;
        }

        .close-btn:hover {
            background: rgba(255, 255, 255, 1);
        }
    </style>
</head>

<body class="bg-gray-50 font-sans text-gray-900">
    <header class="bg-blue-600 text-white text-center py-6">
        <h1 class="text-3xl font-bold">Reporte de Noticias: Avances en Inteligencia Artificial</h1>
    </header>

    <main class="max-w-4xl mx-auto p-6 space-y-6">
        <section class="bg-white shadow-md rounded-lg p-6">
                <h2 class="text-3xl font-bold mb-4 underline">Modelos de IA</h2><div></div><div class="flex items-center justify-between">
                <h3 class="text-2xl font-semibold mb-4">DeepSeek libera modelos R1 open source</h3>
                <div class="mt-0">
                    <button onclick="toggleDropdown(this)" class="text-blue-500 underline bg-transparent border-none p-0">
                        Ver fuente
                    </button>
                    <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="es" dir="ltr">🔴 ¡NUEVOS MODELOS OPEN SOURCE!<br><br>DeepSeek vuelve a poner todo patas arriba cumpliendo su promesa de liberar (open weights) sus modelos R1!<br><br>Modelos disponibles para todos que rinden a la par que el modelo privado más avanzado disponible, o1 de OpenAI 🔥<br><br>¡Increíble noticia! 👇🧵 <a href="https://t.co/IeblB8Bllw">pic.twitter.com/IeblB8Bllw</a></p>&mdash; Carlos Santana (@DotCSV) <a href="https://twitter.com/DotCSV/status/1881323626026115340?ref_src=twsrc%5Etfw">January 20, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                </div>
                
            </div>
            <p class='mt-6'>DeepSeek ha cumplido su promesa y ha liberado sus modelos R1 con open weights, que ofrecen un rendimiento comparable al modelo privado más avanzado de OpenAI, o1. Esta noticia marca un hito en la accesibilidad de modelos de IA de alta calidad.</p><div class="image-container">
                                    <img id="thumbnail" src="https://pbs.twimg.com/media/GhvN2pvXUAAOkqD.png" alt="">
                                </div><div></div><div class="flex items-center justify-between">
                <h3 class="text-2xl font-semibold mb-4">Nuevos Modelos de DeepSeek AI</h3>
                <div class="mt-0">
                    <button onclick="toggleDropdown(this)" class="text-blue-500 underline bg-transparent border-none p-0">
                        Ver fuente
                    </button>
                    <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">The new distilled <a href="https://twitter.com/deepseek_ai?ref_src=twsrc%5Etfw">@deepseek_ai</a> models are fine-tuned versions of <a href="https://twitter.com/Alibaba_Qwen?ref_src=twsrc%5Etfw">@Alibaba_Qwen</a> or <a href="https://twitter.com/AIatMeta?ref_src=twsrc%5Etfw">@AIatMeta</a> Llama 3 using  800k samples curated with DeepSeek-R1. (no RL stage) <a href="https://t.co/2ytEgzZIvv">pic.twitter.com/2ytEgzZIvv</a></p>&mdash; Philipp Schmid (@_philschmid) <a href="https://twitter.com/_philschmid/status/1881319751680733238?ref_src=twsrc%5Etfw">January 20, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                </div>
                
            </div>
            <p class='mt-6'>Los nuevos modelos de <a href="https://x.com/deepseek_ai" class="text-blue-500 underline" target="_blank" rel="noopener noreferrer">@deepseek_ai</a> son versiones afinadas de <a href="https://x.com/Alibaba_Qwen" class="text-blue-500 underline" target="_blank" rel="noopener noreferrer">@Alibaba_Qwen</a> y <a href="https://x.com/AIatMeta" class="text-blue-500 underline" target="_blank" rel="noopener noreferrer">@AIatMeta</a> Llama 3, utilizando 800k muestras curadas con DeepSeek-R1. No incluyen etapa de RL.</p><div class="image-container">
                                    <img id="thumbnail" src="https://pbs.twimg.com/media/GhvKRBgXQAAiAHh.png" alt="">
                                </div><div></div><div class="flex items-center justify-between">
                <h3 class="text-2xl font-semibold mb-4">DeepSeek lanza modelos más pequeños para la comunidad</h3>
                <div class="mt-0">
                    <button onclick="toggleDropdown(this)" class="text-blue-500 underline bg-transparent border-none p-0">
                        Ver fuente
                    </button>
                    <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">yo, deepseek dropping r1 distilled smaller models for the community to play with.<br><br>could they be any more awesome? <a href="https://t.co/iw2fdF0Khq">pic.twitter.com/iw2fdF0Khq</a></p>&mdash; tokenbender (@tokenbender) <a href="https://twitter.com/tokenbender/status/1881315202978951528?ref_src=twsrc%5Etfw">January 20, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                </div>
                
            </div>
            <p class='mt-6'>DeepSeek ha presentado la versión 1 de sus modelos destilados, ofreciendo a la comunidad la oportunidad de experimentar con modelos de IA más accesibles y eficientes.</p><div></div><div class="flex items-center justify-between">
                <h3 class="text-2xl font-semibold mb-4">InternVL 2.5 y FineVideo</h3>
                <div class="mt-0">
                    <button onclick="toggleDropdown(this)" class="text-blue-500 underline bg-transparent border-none p-0">
                        Ver fuente
                    </button>
                    <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">One of the secrets of InternVL 2.5? They added FineVideo in their data mixture 🤩 <a href="https://t.co/FXo4Bk6HnU">pic.twitter.com/FXo4Bk6HnU</a></p>&mdash; Miquel Farré (@micuelll) <a href="https://twitter.com/micuelll/status/1881251735945265166?ref_src=twsrc%5Etfw">January 20, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                </div>
                
            </div>
            <p class='mt-6'>Se ha revelado que el modelo InternVL 2.5 incluye FineVideo en su mezcla de datos, lo que podría ser clave para su rendimiento mejorado en tareas de video.</p><div class="image-container">
                                    <img id="thumbnail" src="https://pbs.twimg.com/media/GhuMAUwXMAAILpS.jpg" alt="">
                                </div><div></div><div class="flex items-center justify-between">
                <h3 class="text-2xl font-semibold mb-4">DeepSeek-R1: un nuevo modelo de código abierto</h3>
                <div class="mt-0">
                    <button onclick="toggleDropdown(this)" class="text-blue-500 underline bg-transparent border-none p-0">
                        Ver fuente
                    </button>
                    <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">RL and open-source for the win!<br><br>The DeepSeek-R1 is a beast though. It still relies on multi-stage training and cold-start data before RL. <br><br>&quot;DeepSeek-R1 achieves performance comparable to OpenAI-o1-1217 on reasoning tasks&quot; <a href="https://t.co/yHgdDN4M1t">https://t.co/yHgdDN4M1t</a> <a href="https://t.co/Ge42ZFq67D">pic.twitter.com/Ge42ZFq67D</a></p>&mdash; elvis (@omarsar0) <a href="https://twitter.com/omarsar0/status/1881363356982153541?ref_src=twsrc%5Etfw">January 20, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                </div>
                
            </div>
            <p class='mt-6'>El modelo DeepSeek-R1 ha sido lanzado y se destaca por su rendimiento comparable al de OpenAI-o1-1217 en tareas de razonamiento. Este modelo es completamente de código abierto y se puede comercializar bajo la licencia MIT.</p><div class="image-container">
                                    <img id="thumbnail" src="https://pbs.twimg.com/media/GhvxQrTWgAIbsuy.png" alt="">
                                </div><div class="image-container">
                                    <img id="thumbnail" src="https://pbs.twimg.com/media/GhvI3AoaAAAw-4z.png" alt="">
                                </div><div></div><div class="flex items-center justify-between">
                <h3 class="text-2xl font-semibold mb-4">Kimi k1.5: un modelo multi-modal de última generación</h3>
                <div class="mt-0">
                    <button onclick="toggleDropdown(this)" class="text-blue-500 underline bg-transparent border-none p-0">
                        Ver fuente
                    </button>
                    <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">🚀 Introducing Kimi k1.5 --- an o1-level multi-modal model<br><br>-Sota short-CoT performance, outperforming GPT-4o and Claude Sonnet 3.5 on 📐AIME, 📐MATH-500, 💻 LiveCodeBench by a large margin (up to +550%)<br>-Long-CoT performance matches o1 across multiple modalities (👀MathVista,… <a href="https://t.co/ZbMcljcsSV">pic.twitter.com/ZbMcljcsSV</a></p>&mdash; Kimi.ai (@Kimi_ai_) <a href="https://twitter.com/Kimi_ai_/status/1881332472748851259?ref_src=twsrc%5Etfw">January 20, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                </div>
                
            </div>
            <p class='mt-6'>Kimi ha presentado su modelo k1.5, que ofrece un rendimiento de última generación en tareas de razonamiento y supera a modelos como GPT-4o y Claude.</p><div></div><div class="flex items-center justify-between">
                <h3 class="text-2xl font-semibold mb-4">Desarrollo de Procesos Computacionales Programables en LLMs</h3>
                <div class="mt-0">
                    <button onclick="toggleDropdown(this)" class="text-blue-500 underline bg-transparent border-none p-0">
                        Ver fuente
                    </button>
                    <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">there&#39;s almost certainly a way to build programmable computing processes inside the weights of an LLM. imma figure out what it is.</p>&mdash; Minh Nhat Nguyen (@menhguin) <a href="https://twitter.com/menhguin/status/1881350685570318707?ref_src=twsrc%5Etfw">January 20, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                </div>
                
            </div>
            <p class='mt-6'>Se sugiere que podría existir una forma de <strong>construir procesos computacionales programables</strong> dentro de los pesos de un modelo de lenguaje grande (LLM).</p><div></div><div class="flex items-center justify-between">
                <h3 class="text-2xl font-semibold mb-4">DeepSeek-R1-Zero vs OpenAI: Comparativa de Rendimiento</h3>
                <div class="mt-0">
                    <button onclick="toggleDropdown(this)" class="text-blue-500 underline bg-transparent border-none p-0">
                        Ver fuente
                    </button>
                    <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Evaluations from the <a href="https://twitter.com/deepseek_ai?ref_src=twsrc%5Etfw">@deepseek_ai</a> paper 💥<br><br>DeepSeek-R1-Zero vs. OpenAI-o1-0912:<br><br>&gt; R1-Zero achieves 71.0% pass@1 on AIME 2024, comparable to OpenAI-o1-0912 (74.4%)<br>&gt; With majority voting, DeepSeek-R1-Zero reaches 86.7%, surpassing OpenAI-o1-0912<br><br>DeepSeek-R1 vs. OpenAI-o1-1217:… <a href="https://t.co/HLE4DND0Mi">https://t.co/HLE4DND0Mi</a></p>&mdash; Vaibhav (VB) Srivastav (@reach_vb) <a href="https://twitter.com/reach_vb/status/1881340583358161148?ref_src=twsrc%5Etfw">January 20, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                </div>
                
            </div>
            <p class='mt-6'>En un reciente estudio, <strong>DeepSeek-R1-Zero</strong> ha alcanzado un <strong>71.0%</strong> en el test <code>AIME 2024</code>, comparándose con el <strong>74.4%</strong> de <strong>OpenAI-o1-0912</strong>. Con votación mayoritaria, DeepSeek-R1-Zero logró un <strong>86.7%</strong>, superando a OpenAI.</p><div class="image-container">
                                    <img id="thumbnail" src="https://pbs.twimg.com/media/GhuC8jKWkAACqPf.jpg" alt="">
                                </div><div></div><div class="flex items-center justify-between">
                <h3 class="text-2xl font-semibold mb-4">DeepSeek-R1-Distill-Qwen-1.5B: Superando a GPT-4o y Claude-3.5</h3>
                <div class="mt-0">
                    <button onclick="toggleDropdown(this)" class="text-blue-500 underline bg-transparent border-none p-0">
                        Ver fuente
                    </button>
                    <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">&quot;DeepSeek-R1-Distill-Qwen-1.5B outperforms GPT-4o and Claude-3.5-Sonnet on math benchmarks with 28.9% on AIME and 83.9% on MATH.&quot;<br><br>1.5B did WHAT? <a href="https://t.co/Pk6fOJNma2">pic.twitter.com/Pk6fOJNma2</a></p>&mdash; Vaibhav (VB) Srivastav (@reach_vb) <a href="https://twitter.com/reach_vb/status/1881319500089634954?ref_src=twsrc%5Etfw">January 20, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                </div>
                
            </div>
            <p class='mt-6'>El modelo <strong>DeepSeek-R1-Distill-Qwen-1.5B</strong> ha demostrado un rendimiento superior en benchmarks matemáticos, alcanzando <strong>28.9%</strong> en <code>AIME</code> y <strong>83.9%</strong> en <code>MATH</code>, superando a <strong>GPT-4o</strong> y <strong>Claude-3.5-Sonnet</strong>.</p><div class="image-container">
                                    <img id="thumbnail" src="https://pbs.twimg.com/media/GhvJ-_XWYAAHmxB.png" alt="">
                                </div><div></div><div class="flex items-center justify-between">
                <h3 class="text-2xl font-semibold mb-4">Modelo de IA de Código Abierto Supera a Competidores</h3>
                <div class="mt-0">
                    <button onclick="toggleDropdown(this)" class="text-blue-500 underline bg-transparent border-none p-0">
                        Ver fuente
                    </button>
                    <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">based af, literally have an open source frontier LLM beating the shit out of sonnet, o1! 💥 <a href="https://t.co/QcvfJ04Q6f">pic.twitter.com/QcvfJ04Q6f</a></p>&mdash; Vaibhav (VB) Srivastav (@reach_vb) <a href="https://twitter.com/reach_vb/status/1881318453048676383?ref_src=twsrc%5Etfw">January 20, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                </div>
                
            </div>
            <p class='mt-6'>Un nuevo modelo de IA de código abierto ha superado a competidores como <strong>Claude-3.5</strong> y <strong>OpenAI</strong> en rendimiento, destacando la innovación en el desarrollo de LLMs (Large Language Models).</p><div class="image-container">
                                    <img id="thumbnail" src="https://pbs.twimg.com/media/GhvI7YXXQAAcax2.jpg" alt="">
                                </div><div></div><div class="flex items-center justify-between">
                <h3 class="text-2xl font-semibold mb-4">DeepSeek lanza R1: Un modelo de IA con 685 mil millones de parámetros</h3>
                <div class="mt-0">
                    <button onclick="toggleDropdown(this)" class="text-blue-500 underline bg-transparent border-none p-0">
                        Ver fuente
                    </button>
                    <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">let’s goo, 685 billion parameters of pure AGI! <a href="https://t.co/9ECPUYpMd3">pic.twitter.com/9ECPUYpMd3</a></p>&mdash; Vaibhav (VB) Srivastav (@reach_vb) <a href="https://twitter.com/reach_vb/status/1881241250789265855?ref_src=twsrc%5Etfw">January 20, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                </div>
                
            </div>
            <p class='mt-6'>DeepSeek ha presentado su nuevo modelo R1, que cuenta con 685 mil millones de parámetros, prometiendo ser una opción robusta en el ámbito de la AGI. Este modelo se destaca por su competitividad en benchmarks de código y su accesibilidad en términos de costo.</p><div class="image-container">
                                    <img id="thumbnail" src="https://pbs.twimg.com/media/GhuC8jKWkAACqPf.jpg" alt="">
                                </div><div></div><div class="flex items-center justify-between">
                <h3 class="text-2xl font-semibold mb-4">Lanzamiento de DeepSeek r1 en Hugging Face</h3>
                <div class="mt-0">
                    <button onclick="toggleDropdown(this)" class="text-blue-500 underline bg-transparent border-none p-0">
                        Ver fuente
                    </button>
                    <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">DeepSeek r1 series is available on <a href="https://twitter.com/huggingface?ref_src=twsrc%5Etfw">@huggingface</a> now!<br><br>Surprises:<br>- It&#39;s not just a single model, it&#39;s a model family<br>- Both big / small reasoning models available giving you more choices<br>- r1 will be in MIT license, allowing for model distillation<br>- Released full training… <a href="https://t.co/2yj58tjTJg">pic.twitter.com/2yj58tjTJg</a></p>&mdash; Tiezhen WANG (@Xianbao_QIAN) <a href="https://twitter.com/Xianbao_QIAN/status/1881316371252015280?ref_src=twsrc%5Etfw">January 20, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                </div>
                
            </div>
            <p class='mt-6'><strong>DeepSeek r1</strong> ya está disponible en <a href="https://huggingface.co">Hugging Face</a>. Este modelo no es solo un modelo único, sino una familia de modelos que promete innovaciones en el campo de la <i>Inteligencia Artificial</i>.</p><div></div><div class="flex items-center justify-between">
                <h3 class="text-2xl font-semibold mb-4">Modelo de razonamiento Deepseek-R1 disponible</h3>
                <div class="mt-0">
                    <button onclick="toggleDropdown(this)" class="text-blue-500 underline bg-transparent border-none p-0">
                        Ver fuente
                    </button>
                    <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">A new completely open reasoning model out of China, Deepseek-R1, is now available. The benchmarks show it at parity with the likes of o1 and Sonnet<br><br>In some informal tests on non-code problems, it is really good, not o1-pro level but surprisingly capable (and small &amp; fast!). Big <a href="https://t.co/w04baHEQQC">pic.twitter.com/w04baHEQQC</a></p>&mdash; Ethan Mollick (@emollick) <a href="https://twitter.com/emollick/status/1881357580372738552?ref_src=twsrc%5Etfw">January 20, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                </div>
                
            </div>
            <p class='mt-6'>Deepseek-R1, un nuevo modelo de razonamiento completamente abierto desarrollado en China, ha mostrado rendimiento comparable a modelos de referencia como o1 y Sonnet. Su tamaño compacto y velocidad lo hacen accesible para computadoras personales.</p><div class="image-container">
                                    <img id="thumbnail" src="https://pbs.twimg.com/media/GhvrddyWoAAfp2w.jpg" alt="">
                                </div><div class="image-container">
                                    <img id="thumbnail" src="https://pbs.twimg.com/media/GhvsFE9W8AAFs7x.jpg" alt="">
                                </div><div class="image-container">
                                    <img id="thumbnail" src="https://pbs.twimg.com/media/GhvsJNiW8AA2TAV.jpg" alt="">
                                </div><div class="image-container">
                                    <img id="thumbnail" src="https://pbs.twimg.com/media/GhvsqVjXYAAlWIh.png" alt="">
                                </div><div></div><div class="flex items-center justify-between">
                <h3 class="text-2xl font-semibold mb-4">Datos Sintéticos para Modelos de Lenguaje</h3>
                <div class="mt-0">
                    <button onclick="toggleDropdown(this)" class="text-blue-500 underline bg-transparent border-none p-0">
                        Ver fuente
                    </button>
                    <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Synthetic data for fine-tuning and evaluating LLMs - private and open source! <br><br>Runs on consumer hardware.<br>Only 15 lines of code<br>Powered by Qwen2.5 32B, MLX and distilabel.<br><br>code: <a href="https://t.co/Y58Vykbfvg">https://t.co/Y58Vykbfvg</a>  <br>data: <a href="https://t.co/bJSkLARCbs">https://t.co/bJSkLARCbs</a> <br>library: <a href="https://t.co/R9IwmIGeuy">https://t.co/R9IwmIGeuy</a> <a href="https://t.co/eZ6oVRcPvg">pic.twitter.com/eZ6oVRcPvg</a></p>&mdash; David Berenstein (@davidberenstei) <a href="https://twitter.com/davidberenstei/status/1881260543291367563?ref_src=twsrc%5Etfw">January 20, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                </div>
                
            </div>
            <p class='mt-6'>Se ha desarrollado una herramienta que permite la generación de datos sintéticos para la fine-tuning y evaluación de modelos de lenguaje (LLMs), que puede ejecutarse en hardware de consumo con solo 15 líneas de código.</p><div class="image-container">
                                    <img id="thumbnail" src="https://pbs.twimg.com/media/GhuUflaXoAA3-CF.jpg" alt="">
                                </div><div></div><div class="flex items-center justify-between">
                <h3 class="text-2xl font-semibold mb-4">Nuevos Modelos de IA: De 1.5B a 70B</h3>
                <div class="mt-0">
                    <button onclick="toggleDropdown(this)" class="text-blue-500 underline bg-transparent border-none p-0">
                        Ver fuente
                    </button>
                    <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">holy fuck, these gigachads dropped 6 distilled models right from 1.5B to 70B 🔥 <a href="https://t.co/DYq0cobPiq">pic.twitter.com/DYq0cobPiq</a></p>&mdash; Vaibhav (VB) Srivastav (@reach_vb) <a href="https://twitter.com/reach_vb/status/1881315419086291213?ref_src=twsrc%5Etfw">January 20, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                </div>
                
            </div>
            <p class='mt-6'>Recientes desarrollos en IA han llevado a la creación de seis modelos destilados, aumentando su capacidad de 1.5B a 70B parámetros, lo que marca un avance significativo en la potencia y eficiencia de los modelos de lenguaje artificial.</p><div class="image-container">
                                    <img id="thumbnail" src="https://pbs.twimg.com/media/GhvGQGJWEAEa1fe.jpg" alt="">
                                </div></section><section class="bg-white shadow-md rounded-lg p-6">
                <h2 class="text-3xl font-bold mb-4 underline">Investigación y Desarrollo</h2><div></div><div class="flex items-center justify-between">
                <h3 class="text-2xl font-semibold mb-4">Análisis del funcionamiento de o1 de OpenAI</h3>
                <div class="mt-0">
                    <button onclick="toggleDropdown(this)" class="text-blue-500 underline bg-transparent border-none p-0">
                        Ver fuente
                    </button>
                    <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="es" dir="ltr">Para los que llevamos meses especulando cómo funciona o1 de OpenAI, el paper de DeepSeek es iluminador, por detalles como que no usan PRMs ni MCTS.<br><br>En OpenAI ya habían dejado entrever que era un único sistema con RL, pero una cosa es leerlo y otra creerlo. <br><br>Parece ser cierto 🤯 <a href="https://t.co/hkaVGiST4F">https://t.co/hkaVGiST4F</a></p>&mdash; Carlos Santana (@DotCSV) <a href="https://twitter.com/DotCSV/status/1881365242896400653?ref_src=twsrc%5Etfw">January 20, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                </div>
                
            </div>
            <p class='mt-6'>Un nuevo paper de DeepSeek proporciona información detallada sobre el funcionamiento del modelo o1 de OpenAI, revelando que no utiliza PRMs ni MCTS, lo que refuerza la idea de que es un sistema único basado en Reinforcement Learning (RL).</p><div></div><div class="flex items-center justify-between">
                <h3 class="text-2xl font-semibold mb-4">Competencia en el mercado de IA</h3>
                <div class="mt-0">
                    <button onclick="toggleDropdown(this)" class="text-blue-500 underline bg-transparent border-none p-0">
                        Ver fuente
                    </button>
                    <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="es" dir="ltr">Ya le toca a OpenAI correr hacia adelante con los modelos o3 para sacar ventaja, porque la ballena china viene por detrás a comerse todo el mercado. <a href="https://t.co/6ptS3LH5bW">pic.twitter.com/6ptS3LH5bW</a></p>&mdash; Carlos Santana (@DotCSV) <a href="https://twitter.com/DotCSV/status/1881328343066525937?ref_src=twsrc%5Etfw">January 20, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                </div>
                
            </div>
            <p class='mt-6'>Se anticipa que OpenAI debe avanzar rápidamente con sus modelos o3, ya que la competencia, especialmente desde China, está aumentando, lo que podría impactar significativamente en su cuota de mercado.</p><video controls class="w-full rounded-lg mb-4 mt-6">
                                    <source src="https://video.twimg.com/tweet_video/GhvSJ2TWwAA3mFk.mp4" type="video/mp4">
                                    Tu navegador no soporta la reproducción de este video.
                                </video><div></div><div class="flex items-center justify-between">
                <h3 class="text-2xl font-semibold mb-4">Perspectivas sobre el Futuro de la IA y su Utilidad</h3>
                <div class="mt-0">
                    <button onclick="toggleDropdown(this)" class="text-blue-500 underline bg-transparent border-none p-0">
                        Ver fuente
                    </button>
                    <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">if this doesn&#39;t kill everyone, then I am 0% personally concerned about my moneymaking prospects. diffusion is slow because most people will never admit AI can be useful. <a href="https://t.co/yUOyDRbOlV">https://t.co/yUOyDRbOlV</a></p>&mdash; Minh Nhat Nguyen (@menhguin) <a href="https://twitter.com/menhguin/status/1881105045439266909?ref_src=twsrc%5Etfw">January 19, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                </div>
                
            </div>
            <p class='mt-6'>Se menciona que, a pesar de la percepción negativa general sobre la IA, se espera un <strong>gran avance</strong> en el desarrollo de <strong>SuperAgentes</strong> a nivel de doctorado, lo que podría cambiar la forma en que se percibe la utilidad de la IA.</p><div></div><div class="flex items-center justify-between">
                <h3 class="text-2xl font-semibold mb-4">Desarrollo de Modelos de IA: Innovaciones Recientes</h3>
                <div class="mt-0">
                    <button onclick="toggleDropdown(this)" class="text-blue-500 underline bg-transparent border-none p-0">
                        Ver fuente
                    </button>
                    <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">holy fuck, these gigachads dropped 6 distilled models right from 1.5B to 70B 🔥 <a href="https://t.co/DYq0cobPiq">pic.twitter.com/DYq0cobPiq</a></p>&mdash; Vaibhav (VB) Srivastav (@reach_vb) <a href="https://twitter.com/reach_vb/status/1881315419086291213?ref_src=twsrc%5Etfw">January 20, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                </div>
                
            </div>
            <p class='mt-6'>Recientes avances en la IA han visto la liberación de <strong>6 modelos destilados</strong> que van desde <strong>1.5B</strong> hasta <strong>70B</strong> parámetros, mostrando un gran potencial en el campo de la <strong>IA General</strong> (AGI).</p><div class="image-container">
                                    <img id="thumbnail" src="https://pbs.twimg.com/media/GhvGQGJWEAEa1fe.jpg" alt="">
                                </div><div></div><div class="flex items-center justify-between">
                <h3 class="text-2xl font-semibold mb-4">Visiones Futuras de la IA</h3>
                <div class="mt-0">
                    <button onclick="toggleDropdown(this)" class="text-blue-500 underline bg-transparent border-none p-0">
                        Ver fuente
                    </button>
                    <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">This point is important. I don’t see clear visions from those seeking very capable AI about what the future world they want looks like<br><br>The singularity (a point at which future predictions become impossible) is a metaphor, not an excuse. What world are you building, specifically? <a href="https://t.co/VY0rn7xiYF">https://t.co/VY0rn7xiYF</a></p>&mdash; Ethan Mollick (@emollick) <a href="https://twitter.com/emollick/status/1881168956779839626?ref_src=twsrc%5Etfw">January 20, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                </div>
                
            </div>
            <p class='mt-6'>No hay una visión clara sobre el futuro deseado que los desarrolladores de IA buscan construir. La singularidad, que sugiere un punto en el que las predicciones del futuro se vuelven imposibles, se presenta como una metáfora que necesita ser concretada en un plan específico.</p><div></div><div class="flex items-center justify-between">
                <h3 class="text-2xl font-semibold mb-4">Desafío de Modelos de IA de China</h3>
                <div class="mt-0">
                    <button onclick="toggleDropdown(this)" class="text-blue-500 underline bg-transparent border-none p-0">
                        Ver fuente
                    </button>
                    <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Can China’s AI Models Challenge OpenAI? A Deep Dive into DeepSeek-R1 ...<br><br>Amidst the fierce race for AI supremacy, a question worth asking is: &quot;Can new AI models from China rival the performance of leading systems like OpenAI’s?&quot; <br><br>A recent paper from DeepSeek introduces their… <a href="https://t.co/QE29RthY33">pic.twitter.com/QE29RthY33</a></p>&mdash; Raphael Mansuy 🍵 (@raphaelmansuy) <a href="https://twitter.com/raphaelmansuy/status/1881323300816838821?ref_src=twsrc%5Etfw">January 20, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                </div>
                
            </div>
            <p class='mt-6'>Un análisis reciente plantea la pregunta de si los nuevos modelos de IA de China pueden rivalizar con sistemas líderes como los de OpenAI. El modelo DeepSeek-R1 es parte de esta competencia en la carrera por la supremacía en IA.</p><div class="image-container">
                                    <img id="thumbnail" src="https://pbs.twimg.com/media/GhvNkTibMAAT_kF.jpg" alt="">
                                </div></section><section class="bg-white shadow-md rounded-lg p-6">
                <h2 class="text-3xl font-bold mb-4 underline">Educación en IA</h2><div></div><div class="flex items-center justify-between">
                <h3 class="text-2xl font-semibold mb-4">Curso de Agentes de IA en Hugging Face</h3>
                <div class="mt-0">
                    <button onclick="toggleDropdown(this)" class="text-blue-500 underline bg-transparent border-none p-0">
                        Ver fuente
                    </button>
                    <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Hugging Face is pre-registering for a free AI Agents course, and over 35,000 people have already signed up in a few days. <a href="https://t.co/srNXZFcoXt">pic.twitter.com/srNXZFcoXt</a></p>&mdash; ℏεsam (@Hesamation) <a href="https://twitter.com/Hesamation/status/1881292274178691271?ref_src=twsrc%5Etfw">January 20, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                </div>
                
            </div>
            <p class='mt-6'>Hugging Face ha abierto preinscripciones para un curso gratuito de Agentes de IA, donde más de 35,000 personas se han registrado en pocos días, destacando el interés en la comunidad de IA.</p><div></div><div class="flex items-center justify-between">
                <h3 class="text-2xl font-semibold mb-4">Gran interés en el curso gratuito de AI Agents de Hugging Face</h3>
                <div class="mt-0">
                    <button onclick="toggleDropdown(this)" class="text-blue-500 underline bg-transparent border-none p-0">
                        Ver fuente
                    </button>
                    <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">35K ppl have already registered, and there&#39;s still time to sign up for the FREE <a href="https://twitter.com/huggingface?ref_src=twsrc%5Etfw">@huggingface</a> AI Agents Course! 🤗<br><br>In this course, you will:<br>→ Learn the fundamentals of <a href="https://twitter.com/hashtag/AIAgents?src=hash&amp;ref_src=twsrc%5Etfw">#AIAgents</a> from scratch<br>→ Build your own AI Agent via the latest libraries<br>→ Earn a certificate<br><br>Link in 🧵↓ <a href="https://t.co/o3g4QyMmcj">pic.twitter.com/o3g4QyMmcj</a></p>&mdash; DataChazGPT (not a bot) (@DataChaz) <a href="https://twitter.com/DataChaz/status/1881290084378648839?ref_src=twsrc%5Etfw">January 20, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                </div>
                
            </div>
            <p class='mt-6'>Más de 35,000 personas ya se han registrado para el curso gratuito de AI Agents de Hugging Face, que promete ser una oportunidad valiosa para aprender sobre inteligencia artificial y sus aplicaciones. Aún hay tiempo para inscribirse.</p><div></div><div class="flex items-center justify-between">
                <h3 class="text-2xl font-semibold mb-4">Introducción a sistemas RAG Agentic</h3>
                <div class="mt-0">
                    <button onclick="toggleDropdown(this)" class="text-blue-500 underline bg-transparent border-none p-0">
                        Ver fuente
                    </button>
                    <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Agentic RAG Overview<br><br>This is a great intro to LLM agents and Agentic RAG.<br><br>It provides a comprehensive exploration of Agentic RAG architectures, applications, and implementation strategies. <a href="https://t.co/rPIXwp3hiL">pic.twitter.com/rPIXwp3hiL</a></p>&mdash; elvis (@omarsar0) <a href="https://twitter.com/omarsar0/status/1881360794019156362?ref_src=twsrc%5Etfw">January 20, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                </div>
                
            </div>
            <p class='mt-6'>Se ha lanzado un curso que ofrece una visión completa sobre arquitecturas de agentes LLM y sistemas RAG Agentic, cubriendo aplicaciones y estrategias de implementación.</p><div class="image-container">
                                    <img id="thumbnail" src="https://pbs.twimg.com/media/Ghvvq8paoAE67YF.jpg" alt="">
                                </div><div></div><div class="flex items-center justify-between">
                <h3 class="text-2xl font-semibold mb-4">Interés en el curso de AI Agents</h3>
                <div class="mt-0">
                    <button onclick="toggleDropdown(this)" class="text-blue-500 underline bg-transparent border-none p-0">
                        Ver fuente
                    </button>
                    <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Wait! Over 35 *thousands* people registered for the AI Agent course<br><br>in a few days...<br><br>time to find the biggest conference center in the world and gather everyone for a giga-conference on agents?<br><br>you can still join the online course here <a href="https://t.co/sdjVw9tcIu">https://t.co/sdjVw9tcIu</a></p>&mdash; Thomas Wolf (@Thom_Wolf) <a href="https://twitter.com/Thom_Wolf/status/1881268455196054001?ref_src=twsrc%5Etfw">January 20, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                </div>
                
            </div>
            <p class='mt-6'>Más de <strong>35,000</strong> personas se han registrado para el curso de <strong>AI Agents</strong>, lo que refleja un creciente interés en el aprendizaje y desarrollo de agentes inteligentes.</p></section><section class="bg-white shadow-md rounded-lg p-6">
                <h2 class="text-3xl font-bold mb-4 underline">Desarrollo y Optimización</h2><div></div><div class="flex items-center justify-between">
                <h3 class="text-2xl font-semibold mb-4">Nuevas funcionalidades en ChatGPT para macOS</h3>
                <div class="mt-0">
                    <button onclick="toggleDropdown(this)" class="text-blue-500 underline bg-transparent border-none p-0">
                        Ver fuente
                    </button>
                    <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="es" dir="ltr">Menciones a Operator (&quot;agentes&quot;) en la app de mac de ChatGPT <a href="https://t.co/C5AbXivSFW">https://t.co/C5AbXivSFW</a></p>&mdash; Carlos Santana (@DotCSV) <a href="https://twitter.com/DotCSV/status/1881111338090709296?ref_src=twsrc%5Etfw">January 19, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                </div>
                
            </div>
            <p class='mt-6'>La aplicación de ChatGPT para macOS incluye opciones ocultas para definir atajos que permiten alternar y forzar la salida de "Operator", lo que sugiere una expansión en las funcionalidades de la aplicación.</p><div></div><div class="flex items-center justify-between">
                <h3 class="text-2xl font-semibold mb-4">Desarrollo de Evaluaciones Automáticas en IA</h3>
                <div class="mt-0">
                    <button onclick="toggleDropdown(this)" class="text-blue-500 underline bg-transparent border-none p-0">
                        Ver fuente
                    </button>
                    <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">benchmark idea: what is there was a way to automatically scrape+ index problems by level of complexity * how rare the required solution steps are to find on the internet? this way you also don&#39;t have to painstakingly make harder and harder evals <a href="https://t.co/gTXBxIfmNm">https://t.co/gTXBxIfmNm</a></p>&mdash; Minh Nhat Nguyen (@menhguin) <a href="https://twitter.com/menhguin/status/1881353800847622422?ref_src=twsrc%5Etfw">January 20, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                </div>
                
            </div>
            <p class='mt-6'>Se propone la idea de un sistema que permita <strong>raspar e indexar problemas</strong> según su nivel de complejidad y la rareza de sus soluciones en Internet. Esto podría facilitar la creación de evaluaciones más desafiantes sin el esfuerzo manual habitual.</p><div></div><div class="flex items-center justify-between">
                <h3 class="text-2xl font-semibold mb-4">Capacidades Emergentes en Modelos de IA</h3>
                <div class="mt-0">
                    <button onclick="toggleDropdown(this)" class="text-blue-500 underline bg-transparent border-none p-0">
                        Ver fuente
                    </button>
                    <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Random speculation: if model scaling allows more params to capture richer more diverse representations within a large dataset, then a bottleneck to pure scaling is how well we can test the countless tail-end capabilities Dario Amodei talkes about.</p>&mdash; Minh Nhat Nguyen (@menhguin) <a href="https://twitter.com/menhguin/status/1881334840018309343?ref_src=twsrc%5Etfw">January 20, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                </div>
                
            </div>
            <p class='mt-6'>Se discute la posibilidad de que el <strong>escalado de modelos</strong> permita capturar representaciones más ricas y diversas dentro de grandes conjuntos de datos. Sin embargo, se señala que un posible <strong>cuello de botella</strong> es la capacidad de probar las numerosas capacidades menos comunes mencionadas por Dario Amodei.</p><div></div><div class="flex items-center justify-between">
                <h3 class="text-2xl font-semibold mb-4">Dificultades en la Evaluación de Preguntas Complejas</h3>
                <div class="mt-0">
                    <button onclick="toggleDropdown(this)" class="text-blue-500 underline bg-transparent border-none p-0">
                        Ver fuente
                    </button>
                    <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">You&#39;d think that the central mass of evals that everyone can agree on (uni-level coursework) would be covered by now, while questions requiring multiple esoteric concepts are not as well-tested. This is possibly why GPQA is still so hard to crack.</p>&mdash; Minh Nhat Nguyen (@menhguin) <a href="https://twitter.com/menhguin/status/1881334854056628694?ref_src=twsrc%5Etfw">January 20, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                </div>
                
            </div>
            <p class='mt-6'>A pesar de que se espera que las evaluaciones comunes como los trabajos universitarios estén bien cubiertas, se observa que las preguntas que requieren múltiples conceptos esotéricos aún no están suficientemente probadas. Esto podría explicar la dificultad de GPQA.</p><div></div><div class="flex items-center justify-between">
                <h3 class="text-2xl font-semibold mb-4">Mejoras en evaluación de LLMs en Meta</h3>
                <div class="mt-0">
                    <button onclick="toggleDropdown(this)" class="text-blue-500 underline bg-transparent border-none p-0">
                        Ver fuente
                    </button>
                    <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">A new year, a new challenge.<br><br>I recently joined <a href="https://twitter.com/AIatMeta?ref_src=twsrc%5Etfw">@AIatMeta</a> to improve evaluation and benchmarking of LLMs. I&#39;m excited to push on making LLMs more useful and accessible, via open-sourcing data/models and real-world applications. I&#39;ll continue to be based in Berlin.</p>&mdash; Sebastian Ruder (@seb_ruder) <a href="https://twitter.com/seb_ruder/status/1880978423440654550?ref_src=twsrc%5Etfw">January 19, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                </div>
                
            </div>
            <p class='mt-6'><strong>Seb Ruder</strong> se ha unido a <i>AI at Meta</i> para mejorar la evaluación y el <i>benchmarking</i> de <strong>LLMs</strong>, lo que indica un enfoque renovado en la calidad de los modelos de lenguaje.</p></section><section class="bg-white shadow-md rounded-lg p-6">
                <h2 class="text-3xl font-bold mb-4 underline">Generación de Contenido</h2><div></div><div class="flex items-center justify-between">
                <h3 class="text-2xl font-semibold mb-4">Nuevos avances en generación de video</h3>
                <div class="mt-0">
                    <button onclick="toggleDropdown(this)" class="text-blue-500 underline bg-transparent border-none p-0">
                        Ver fuente
                    </button>
                    <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Current best open source video generation model?</p>&mdash; clem 🤗 (@ClementDelangue) <a href="https://twitter.com/ClementDelangue/status/1881018041963802742?ref_src=twsrc%5Etfw">January 19, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                </div>
                
            </div>
            <p class='mt-6'>Se discute cuál es el mejor modelo de código abierto para la generación de video actualmente, lo que refleja el interés creciente en esta área de la inteligencia artificial.</p><div></div><div class="flex items-center justify-between">
                <h3 class="text-2xl font-semibold mb-4">Generación de video con modelos de código abierto</h3>
                <div class="mt-0">
                    <button onclick="toggleDropdown(this)" class="text-blue-500 underline bg-transparent border-none p-0">
                        Ver fuente
                    </button>
                    <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Current best open source video generation model?</p>&mdash; clem 🤗 (@ClementDelangue) <a href="https://twitter.com/ClementDelangue/status/1881018041963802742?ref_src=twsrc%5Etfw">January 19, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                </div>
                
            </div>
            <p class='mt-6'>Se discute sobre el mejor modelo de <strong>generación de video</strong> de código abierto, lo que sugiere avances en la creación de contenidos multimedia mediante <i>IA</i>.</p><div></div><div class="flex items-center justify-between">
                <h3 class="text-2xl font-semibold mb-4">Innovaciones en generación de contenido visual</h3>
                <div class="mt-0">
                    <button onclick="toggleDropdown(this)" class="text-blue-500 underline bg-transparent border-none p-0">
                        Ver fuente
                    </button>
                    <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">How does veo 2 pull off three nervous women holding knives on the back of a giant caterpillar running through a deserted city looking determined as a tank rolls towards them?<br><br>If I imagine a thing, I can generate something close. It isn&#39;t a replacement for film, it is a new thing <a href="https://t.co/AslrMQX1st">pic.twitter.com/AslrMQX1st</a></p>&mdash; Ethan Mollick (@emollick) <a href="https://twitter.com/emollick/status/1881229882598011029?ref_src=twsrc%5Etfw">January 20, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                </div>
                
            </div>
            <p class='mt-6'>Se están desarrollando nuevas capacidades en generación de imágenes a partir de descripciones complejas, como la creación de escenas surrealistas. Esto representa un avance significativo en la generación de contenido multimedia mediante IA.</p><video controls class="w-full rounded-lg mb-4 mt-6">
                                    <source src="https://video.twimg.com/ext_tw_video/1881229740138184704/pu/vid/avc1/1280x720/WPJyRvDlj3stmzBv.mp4?tag=12" type="video/mp4">
                                    Tu navegador no soporta la reproducción de este video.
                                </video><div></div><div class="flex items-center justify-between">
                <h3 class="text-2xl font-semibold mb-4">Desafíos en la Generación de Video con IA</h3>
                <div class="mt-0">
                    <button onclick="toggleDropdown(this)" class="text-blue-500 underline bg-transparent border-none p-0">
                        Ver fuente
                    </button>
                    <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">There is still a very large gap between the control that film gives to creators and the strangeness of using AI video generators which involves more randomness. The gap may be closed eventually (soon?)  but for now you c an create some interesting, if incoherent, videos easily.</p>&mdash; Ethan Mollick (@emollick) <a href="https://twitter.com/emollick/status/1881231177773928666?ref_src=twsrc%5Etfw">January 20, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                </div>
                
            </div>
            <p class='mt-6'>Actualmente existe una brecha significativa entre el control que ofrecen las herramientas de video tradicionales a los creadores y la aleatoriedad de los generadores de video basados en IA. Aunque se espera que esta brecha se cierre pronto, por ahora, la creación de videos interesantes pero incoherentes es una realidad accesible.</p></section><section class="bg-white shadow-md rounded-lg p-6">
                <h2 class="text-3xl font-bold mb-4 underline">API y Economía de la IA</h2><div></div><div class="flex items-center justify-between">
                <h3 class="text-2xl font-semibold mb-4">Comparativa de costos entre DeepSeek R1 y OpenAI 01</h3>
                <div class="mt-0">
                    <button onclick="toggleDropdown(this)" class="text-blue-500 underline bg-transparent border-none p-0">
                        Ver fuente
                    </button>
                    <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Wow! Deepseeks R1 is over 27x cheaper than 01 🤯<br><br>Deepseek Reasoner<br>• $0.55 / 1M Input<br>• $2.19 / 1M Output<br><br>OpenAI 01<br>• $15 / 1M Input<br>• $60 / 1M Output<br><br>and you have tons of opens if you want an alternative for 01-mini with the R1 distilled models</p>&mdash; Caleb (@calebfahlgren) <a href="https://twitter.com/calebfahlgren/status/1881332657885413886?ref_src=twsrc%5Etfw">January 20, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                </div>
                
            </div>
            <p class='mt-6'>El nuevo modelo DeepSeek R1 es más de 27 veces más económico que OpenAI 01, ofreciendo tarifas de $0.55 por 1M de input y $2.19 por 1M de output, en comparación con $15 y $60 respectivamente para OpenAI 01. Esto resalta la accesibilidad de R1 para desarrolladores.</p><div></div><div class="flex items-center justify-between">
                <h3 class="text-2xl font-semibold mb-4">Acceso y precios de DeepSeek R1</h3>
                <div class="mt-0">
                    <button onclick="toggleDropdown(this)" class="text-blue-500 underline bg-transparent border-none p-0">
                        Ver fuente
                    </button>
                    <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Source<a href="https://t.co/CnpY3Mf6nl">https://t.co/CnpY3Mf6nl</a></p>&mdash; Caleb (@calebfahlgren) <a href="https://twitter.com/calebfahlgren/status/1881333186615222776?ref_src=twsrc%5Etfw">January 20, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                </div>
                
            </div>
            <p class='mt-6'>DeepSeek ha anunciado su API para el modelo R1, con precios de $0.14 por millón de tokens de entrada en caso de cache hit y $0.55 en caso de cache miss. Esta estructura de precios es atractiva para empresas y desarrolladores que buscan alternativas a modelos más costosos.</p><div class="image-container">
                                    <img id="thumbnail" src="https://pbs.twimg.com/media/GhvICi1a0AAoVhW.jpg" alt="">
                                </div><div class="image-container">
                                    <img id="thumbnail" src="https://pbs.twimg.com/media/GhvIDGSaIAEyj9d.jpg" alt="">
                                </div></section><section class="bg-white shadow-md rounded-lg p-6">
                <h2 class="text-3xl font-bold mb-4 underline">Comunidad y Ética</h2><div></div><div class="flex items-center justify-between">
                <h3 class="text-2xl font-semibold mb-4">Participación activa en discusiones de Hugging Face</h3>
                <div class="mt-0">
                    <button onclick="toggleDropdown(this)" class="text-blue-500 underline bg-transparent border-none p-0">
                        Ver fuente
                    </button>
                    <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Discussions under Hugging Face articles is a very good way to engage with the post authors.<a href="https://t.co/jq9Afnkrfo">https://t.co/jq9Afnkrfo</a> <a href="https://t.co/844j1fZFBr">pic.twitter.com/844j1fZFBr</a></p>&mdash; Aritra Roy Gosthipaty (@ariG23498) <a href="https://twitter.com/ariG23498/status/1881237555993252103?ref_src=twsrc%5Etfw">January 20, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                </div>
                
            </div>
            <p class='mt-6'>Las discusiones bajo los artículos de <strong>Hugging Face</strong> son una excelente forma de interactuar con los autores de las publicaciones, promoviendo el intercambio de ideas en la comunidad de <i>IA</i>.</p><div class="image-container">
                                    <img id="thumbnail" src="https://pbs.twimg.com/media/Ght_YOVaYAAM4an.jpg" alt="">
                                </div><div></div><div class="flex items-center justify-between">
                <h3 class="text-2xl font-semibold mb-4">Seguridad de Agentes de IA en Entornos Reales</h3>
                <div class="mt-0">
                    <button onclick="toggleDropdown(this)" class="text-blue-500 underline bg-transparent border-none p-0">
                        Ver fuente
                    </button>
                    <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">How Do We Safeguard AI Agents Operating in the Wild?<br><br>As AI agents become more autonomous and capable of acting in real-world environments, we face a pressing question: &quot;How do we manage the risks associated with these agents, ensuring they operate safely and ethically?&quot; <br><br>The…</p>&mdash; Raphael Mansuy 🍵 (@raphaelmansuy) <a href="https://twitter.com/raphaelmansuy/status/1881172263996936247?ref_src=twsrc%5Etfw">January 20, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                </div>
                
            </div>
            <p class='mt-6'>A medida que los agentes de IA se vuelven más autónomos y capaces de operar en entornos reales, surge la pregunta crítica sobre cómo gestionar los riesgos asociados y garantizar su funcionamiento seguro y ético.</p></section><section class="bg-white shadow-md rounded-lg p-6">
                <h2 class="text-3xl font-bold mb-4 underline">Interacción y Automatización</h2><div></div><div class="flex items-center justify-between">
                <h3 class="text-2xl font-semibold mb-4">Optimización de Modelos de Razonamiento</h3>
                <div class="mt-0">
                    <button onclick="toggleDropdown(this)" class="text-blue-500 underline bg-transparent border-none p-0">
                        Ver fuente
                    </button>
                    <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">There are no rigorous studies yet on how to best prompt reasoning models like o1.<br><br>They are not chat models, they are designed so that you give them a question and you get an answer. You want to give them context, etc. but we don’t know what the optimal way to do that is yet.</p>&mdash; Ethan Mollick (@emollick) <a href="https://twitter.com/emollick/status/1881047173011575133?ref_src=twsrc%5Etfw">January 19, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div><div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">I see formulas and prompting techniques being passed around virally, just like we saw in the early days of ChatGPT. Are these the best approaches? Are they even good? We don’t know yet.</p>&mdash; Ethan Mollick (@emollick) <a href="https://twitter.com/emollick/status/1881047575480172957?ref_src=twsrc%5Etfw">January 19, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                </div>
                
            </div>
            <p class='mt-6'>Aún no se han realizado estudios rigurosos sobre la mejor manera de interactuar con modelos de razonamiento como el o1. Estos modelos requieren un enfoque específico para obtener respuestas adecuadas, y actualmente no se conocen las mejores prácticas.</p><div></div><div class="flex items-center justify-between">
                <h3 class="text-2xl font-semibold mb-4">Automatización de Flujos de Trabajo con IA</h3>
                <div class="mt-0">
                    <button onclick="toggleDropdown(this)" class="text-blue-500 underline bg-transparent border-none p-0">
                        Ver fuente
                    </button>
                    <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">🤔 What If You Could Automate Complex Workflows Using Plain English?<br><br>Imagine being able to delegate tasks like market research, press reviews, or AI article analysis—all by simply describing what you need in plain English. <br><br>Sounds like magic, right? ....<br><br>Well, it’s now a…</p>&mdash; Raphael Mansuy 🍵 (@raphaelmansuy) <a href="https://twitter.com/raphaelmansuy/status/1881248558252433792?ref_src=twsrc%5Etfw">January 20, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                </div>
                
            </div>
            <p class='mt-6'>La posibilidad de automatizar flujos de trabajo complejos utilizando lenguaje natural se está convirtiendo en una realidad. Esto permitiría delegar tareas como investigación de mercado o análisis de artículos de IA simplemente describiendo lo que se necesita en inglés sencillo.</p></section><section class="bg-white shadow-md rounded-lg p-6">
                <h2 class="text-3xl font-bold mb-4 underline">Gestión y Productividad</h2><div></div><div class="flex items-center justify-between">
                <h3 class="text-2xl font-semibold mb-4">Impacto de la IA en la Productividad</h3>
                <div class="mt-0">
                    <button onclick="toggleDropdown(this)" class="text-blue-500 underline bg-transparent border-none p-0">
                        Ver fuente
                    </button>
                    <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Technologies do not revolutionize productivity immediately, at least historically<br><br>You could potentially argue that AI is different for a variety of reasons, but it would be smart to acknowledge the default expectation is that it will be years until the real impact of AI on work. <a href="https://t.co/QKVr5lbPzd">https://t.co/QKVr5lbPzd</a></p>&mdash; Ethan Mollick (@emollick) <a href="https://twitter.com/emollick/status/1881070444524261682?ref_src=twsrc%5Etfw">January 19, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                </div>
                
            </div>
            <p class='mt-6'>Históricamente, las tecnologías no revolucionan la productividad de inmediato. Aunque se podría argumentar que la IA es diferente, es prudente reconocer que pueden pasar años antes de que se vea su impacto real en el trabajo.</p><div></div><div class="flex items-center justify-between">
                <h3 class="text-2xl font-semibold mb-4">Gestión de Documentos de Requerimientos de Producto</h3>
                <div class="mt-0">
                    <button onclick="toggleDropdown(this)" class="text-blue-500 underline bg-transparent border-none p-0">
                        Ver fuente
                    </button>
                    <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">For everyone asking how I create PRDs:<br><br>Writing PRDs used to take forever, until I discovered this workflow that’s fast AND delivers top-tier results.<br><br>Here’s how I do it:<br><br>1. Start by throwing everything the client shared into ChatGPT.<br>2. Ask it to list core features + nice…</p>&mdash; Prajwal Tomar (@PrajwalTomar_) <a href="https://twitter.com/PrajwalTomar_/status/1880628902680199401?ref_src=twsrc%5Etfw">January 18, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                </div>
                
            </div>
            <p class='mt-6'>Un nuevo flujo de trabajo ha revolucionado la creación de Documentos de Requerimientos de Producto (PRDs), permitiendo que este proceso sea más rápido y eficiente, lo que es crucial en el desarrollo de productos impulsados por IA.</p></section>
    </main>

    <footer class="bg-blue-600 text-white text-center py-4">
        <p>&copy; 2025 Todos los derechos reservados. Reporte de Noticias - Inteligencia Artificial</p>
    </footer>

    <div id="popup-image" class="popup-overlay">
        <button class="close-btn" id="close-btn-image">X</button>
        <img id="popup-image-content" src="" alt="Imagen ampliada">
    </div>

    <div id="popup-content" class="popup-overlay">
        <button class="close-btn" id="close-btn-content">X</button>
        <div id="popup-html-content" class="p-4">
        </div>
    </div>

    <script>
        // Elementos del DOM
        const thumbnails = document.querySelectorAll('.image-container img');
        const popupImage = document.getElementById('popup-image');
        const popupContent = document.getElementById('popup-content'); // Popup para contenido HTML
        const closeBtnImage = document.getElementById('close-btn-image'); // Botón de cierre del popup de imagen
        const closeBtnContent = document.getElementById('close-btn-content'); // Botón de cierre del popup de contenido HTML

        // Variables para el zoom
        let isZoomedIn = false;
        let isDragging = false;
        let startX, startY, translateX = 0, translateY = 0;

        // Evento para mostrar el popup de imagen
        thumbnails.forEach(thumbnail => {
            thumbnail.addEventListener('click', () => {
                popupImage.src = thumbnail.src; // Carga la imagen
                document.getElementById('popup-image-overlay').classList.add('show'); // Muestra el popup de imagen
            });
        });

        // Evento para cerrar el popup de imagen
        closeBtnImage.addEventListener('click', () => {
            document.getElementById('popup-image-overlay').classList.remove('show');
            resetZoom();
        });

        // Evento para mostrar el popup de contenido HTML
        function toggleDropdown(button) {
            const dropdown = button.nextElementSibling;
            const allLinksHTML = dropdown.innerHTML; // El contenido HTML de los enlaces

            if (dropdown.classList.contains("hidden")) {
                dropdown.classList.remove("hidden");

                // Mostrar el contenido dentro del popup de contenido HTML
                popupContent.innerHTML = allLinksHTML; // Inserta el contenido HTML en el popup
                document.getElementById('popup-content-overlay').classList.add('show'); // Muestra el popup con el contenido HTML
            } else {
                dropdown.classList.add("hidden");
                document.getElementById('popup-content-overlay').classList.remove('show'); // Cierra el popup de contenido HTML
            }
        }

        // Evento para cerrar el popup de contenido HTML
        closeBtnContent.addEventListener('click', () => {
            document.getElementById('popup-content-overlay').classList.remove('show');
            popupContent.innerHTML = ''; // Limpia el contenido del popup
        });

        // Click para alternar entre zoom in y zoom out en la imagen
        popupImage.addEventListener('click', () => {
            if (isZoomedIn) {
                resetZoom();
            } else {
                zoomIn();
            }
        });

        // Drag para mover la imagen mientras está ampliada
        popupImage.addEventListener('mousedown', (e) => {
            if (!isZoomedIn) return;
            isDragging = true;
            startX = e.clientX - translateX;
            startY = e.clientY - translateY;
            popupImage.style.cursor = 'grabbing';
        });

        popupImage.addEventListener('mousemove', (e) => {
            if (!isDragging) return;
            translateX = e.clientX - startX;
            translateY = e.clientY - startY;
            updateTransform();
        });

        popupImage.addEventListener('mouseup', () => {
            isDragging = false;
            popupImage.style.cursor = 'grab';
        });

        popupImage.addEventListener('mouseleave', () => {
            isDragging = false;
            popupImage.style.cursor = 'grab';
        });

        // Funciones de zoom
        function zoomIn() {
            isZoomedIn = true;
            popupImage.style.transform = `scale(2)`;
            popupImage.style.cursor = 'grab';
        }

        function resetZoom() {
            isZoomedIn = false;
            translateX = 0;
            translateY = 0;
            popupImage.style.transform = `scale(1)`;
        }

        // Actualizar posición durante el drag
        function updateTransform() {
            popupImage.style.transform = `scale(2) translate(${translateX}px, ${translateY}px)`;
        }

    </script>

</body>