<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Reporte de Noticias - Inteligencia Artificial</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        .image-container {
            max-width: 500px;
            max-height: 500px;
            overflow: hidden;
            border: 2px solid #ccc;
            border-radius: 10px;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
            position: relative;
            margin: 0 auto;
        }

        .image-container img {
            width: 100%;
            height: auto;
            cursor: pointer;
            object-fit: cover;
        }

        /* Popup */
        .popup-overlay {
            display: none;
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0, 0, 0, 0.8);
            justify-content: center;
            align-items: center;
            z-index: 1000;
        }

        .popup-overlay img {
            max-width: 100%;
            max-height: 100%;
            cursor: grab;
            transition: transform 0.3s;
        }

        .popup-overlay.show {
            display: flex;
        }

        /* Botón de cierre */
        .close-btn {
            position: absolute;
            top: 20px;
            right: 20px;
            background: rgba(255, 255, 255, 0.8);
            border: none;
            font-size: 18px;
            font-weight: bold;
            cursor: pointer;
            padding: 5px 10px;
            border-radius: 5px;
            z-index: 1100;
        }

        .close-btn:hover {
            background: rgba(255, 255, 255, 1);
        }
    </style>
</head>
<body class="bg-gray-50 font-sans text-gray-900">
    <header class="bg-blue-600 text-white text-center py-6">
        <h1 class="text-3xl font-bold">Reporte de Noticias: Avances en Inteligencia Artificial</h1>
    </header>

    <main class="max-w-4xl mx-auto p-6 space-y-6">
        <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Análisis de la Inteligencia Artificial en 2024</h2><p class='mt-6'>Un nuevo video ha sido publicado en el canal de DotCSV, donde se discute el análisis de la inteligencia artificial para el año 2024. El video presenta una perspectiva profunda sobre el futuro de la tecnología y sus implicaciones.</p>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="es" dir="ltr">🔥 ¡NUEVO VIDEO EN EL LAB! 🔥<br><br>Si aún no habéis tenido oportunidad de ver mi directo analizado la IA en 2024, os he preparado un resumen de 25 minutos con los momentos claves!<br><br>Tenéis el link a continuación 👇 <a href="https://t.co/kW1MSMkfjW">pic.twitter.com/kW1MSMkfjW</a></p>&mdash; Carlos Santana (@DotCSV) <a href="https://twitter.com/DotCSV/status/1878487122023501946?ref_src=twsrc%5Etfw">January 12, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Innovaciones en Moda Digital</h2><p class='mt-6'>Recientemente se ha comentado sobre la posibilidad de crear imágenes y videos que permiten probar ropa de manera virtual. Esta tecnología, que hace unos años parecía pertenecer al ámbito de la ciencia ficción, se ha vuelto mucho más accesible gracias a la combinación de varios modelos de código abierto disponibles.</p><video controls class="w-full rounded-lg mb-4 mt-6">
                                        <source src="https://video.twimg.com/ext_tw_video/1878514710204628993/pu/vid/avc1/1196x720/0zs66_lPtKxObzQV.mp4?tag=12" type="video/mp4">
                                        Tu navegador no soporta la reproducción de este video.
                                    </video>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="es" dir="ltr">Crear imágenes y vídeos probándote ropa 👍<br><br>Lo que hace unos años hubiera parecido ciencia ficción ahora es bastante trivial de implementar combinando varios de los modelos open source disponibles.<a href="https://t.co/9jHlLQ0IZD">pic.twitter.com/9jHlLQ0IZD</a></p>&mdash; Carlos Santana (@DotCSV) <a href="https://twitter.com/DotCSV/status/1878733163372990619?ref_src=twsrc%5Etfw">January 13, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Deduplicación de Datos en Modelos de Lenguaje</h2><p class='mt-6'>Philipp Schmid ha compartido noticias sobre el proceso de deduplicación del conjunto de datos The-Tome.</p><p class='mt-6'>Con un umbral de similitud de 0.98, se logró deduplicar 1,169,484 prompts, eliminando un total de 582,989 debido a la duplicación, que representa un ratio de duplicados del 0.33%.</p><p class='mt-6'>El proceso de deduplicación tomó 150.52 segundos en un dispositivo tipo M1, mostrando la eficiencia de esta operación en entornos de entrenamiento de modelos de lenguaje. Sostiene que la deduplicación y la prevención de fuga de datos son esenciales al entrenar modelos de lenguaje de gran tamaño.</p><p class='mt-6'>Una herramienta clave en este proceso es SemHash, una biblioteca de deduplicación semántica rápida que hace uso de embeddings de Model2Vec combinados con búsquedas de similitud basadas en vecinos, permitiendo deduplicar millones de registros de manera efectiva.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhL2YjhX0AA-x_H.jpg" alt="">
                                    </div><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhKjdqZW8AA8skS.jpg" alt="">
                                    </div>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2">https://x.com/_philschmid/status/1878835058259505446.</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Resumen de SemHash</h2><p class='mt-6'>SemHash es una nueva biblioteca de deduplicación que se destaca por su rapidez y eficacia.</p><p class='mt-6'>Se combina con métodos de búsqueda avanzada para optimizar la deduplicación de texto, lo que resulta crucial en la administración de conjuntos de datos masivos en proyectos de aprendizaje automático.</p></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Observaciones Finales</h2><p class='mt-6'>La deduplicación efectiva es un punto crítico para lograr resultados de calidad en el entrenamiento de modelos de lenguaje, ya que ayuda a minimizar la redundancia de datos y a mejorar el rendimiento del modelo.</p></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Plan de Oportunidades en Inteligencia Artificial del Reino Unido</h2><p class='mt-6'>Elprimer ministro del Reino Unido ha publicado el Plan de Oportunidades en Inteligencia Artificial, el cual se compromete a implementar todas sus recomendaciones.</p><p class='mt-6'>Este plan tiene como objetivo potenciar la comunidad de inteligencia artificial de código abierto en el Reino Unido, que ya es considerada de alta calidad.</p><p class='mt-6'>El enfoque del plan es claro, prestando atención a datos, energía y empleo.</p><p class='mt-6'>La comunidad de inteligencia artificial en el Reino Unido está entusiasmada por las oportunidades que este plan traerá.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhK9y-2WoAAfZoF.jpg'>" alt="">
                                    </div>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Clear plan and love the attention to data, energy, and jobs! The UK&#39;s open-source AI community is already top notch, excited to see it bloom even more. <a href="https://t.co/Bol2akSCMG">https://t.co/Bol2akSCMG</a></p>&mdash; clem 🤗 (@ClementDelangue) <a href="https://twitter.com/ClementDelangue/status/1878815092588036606?ref_src=twsrc%5Etfw">January 13, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Reflexiones sobre el Bilingüismo</h2><p class='mt-6'>Se ha destacado que ser bilingüe no solo implica hablar dos idiomas, sino también pensar y razonar en ambos.</p><p class='mt-6'>Esta perspectiva resalta la complejidad y riqueza que aporta el bilingüismo en la vida diaria de las personas, así como en la comprensión cultural.</p>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">I&#39;ve always felt that being bilingual isn&#39;t just about speaking two languages--it&#39;s about THINKING and muttering in whichever language feels more natural depending on the topic and context. For example, I prefer doing math in Chinese because each digit is just one syllable, which… <a href="https://t.co/yD2YNscWW5">https://t.co/yD2YNscWW5</a></p>&mdash; Tiezhen WANG (@Xianbao_QIAN) <a href="https://twitter.com/Xianbao_QIAN/status/1878623350953857166?ref_src=twsrc%5Etfw">January 13, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Recursos en Aprendizaje Automático</h2><p class='mt-6'>Cuatro grandes recursos en el campo del aprendizaje automático para iniciar la semana:</p><p class='mt-6'>1. Datos sintéticos y modelos pequeños en 2024.</p><p class='mt-6'>2. Una guía visual de Mamba y modelos de espacio de estado.</p><p class='mt-6'>3. Transformers de bytes latentes: Los parches escalan mejor que los tokens.</p><p class='mt-6'>4. Modelos conceptuales grandes: Modelado del lenguaje en un espacio de representación de oraciones.</p></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Transformadores de Bytes Latentes</h2><p class='mt-6'>Un interesante estudio presenta una arquitectura de modelo de lenguaje grande que elimina los tokens y utiliza parches de bytes dinámicos en su lugar. Este enfoque ha logrado métricas destacadas comparado con otros modelos y consume menos operaciones de punto flotante por segundo (FLOPs).</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhHvaIvXgAAuq4t.jpg" alt="">
                                    </div></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Modelos Conceptuales Grandes</h2><p class='mt-6'>El cuarto recurso investiga la predicción de conceptos (incrustaciones de oraciones) en lugar de la predicción de tokens. Los autores analizan arquitecturas basadas en difusión y un espacio multimodal y multilingüe.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhHv9WgWwAAO2Ub.jpg" alt="">
                                    </div></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Innovaciones en Modelos de Lenguaje</h2><p class='mt-6'>Se ha presentado un marco nuevo llamado <strong>VideoRAG</strong>. Este sistema mejora la recuperación de documentos relevantes mediante el uso de contenido de video como fuente de conocimiento externa. A diferencia de otros enfoques que se centran en texto o imágenes, VideoRAG recupera videos relevantes en función de las consultas y los incorpora para proporcionar contexto adicional.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhLvhKVbsAAJbwE.jpg"" alt="">
                                    </div><p class='mt-6'>El estudio <strong>“Pequeños Modelos de Lenguaje Pueden Ser Poderosos”</strong> reseña alrededor de 160 trabajos que demuestran el potencial de los pequeños modelos de lenguaje. Este análisis se enfoca en modelos de uso general, modelos específicos de tareas y técnicas para crearlos.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhLsyHvaIAAggew.jpg"" alt="">
                                    </div><p class='mt-6'>También se explora el futuro de la inteligencia artificial a través de <strong>Grandes Modelos de Concepto</strong>, recientemente introducidos por Meta, que tienen el potencial de revolucionar diversas aplicaciones en el campo.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhLrZdhbYAAfL-7.png"" alt="">
                                    </div></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Avances en Capacidades de Recuperación de Información</h2><p class='mt-6'>El sistema denominado <strong>LLMQuoter</strong> mejora las capacidades de recuperación mediante una estrategia de <em>“citar primero y luego responder”</em>. Este sistema utiliza Llama-3B y se finetunea con LoRA en un subconjunto de 15,000 muestras de HotPotQA, identificando citas clave antes de enviarlas a modelos de razonamiento.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhLo4d7bcAA-3Q9.png"" alt="">
                                    </div></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Nuevas Estrategias de Ajuste de Modelos</h2><p class='mt-6'>Se introduce el enfoque de <strong>ajuste multiagente</strong>, que mejora modelos de lenguaje a través del auto-mejoramiento. A diferencia de los métodos tradicionales de ajuste de un solo agente, que tienden a estancarse después de algunas iteraciones, este método utiliza una sociedad de modelos de lenguaje para alcanzar mejores resultados.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhLlclWboAAa4Mi.jpg"" alt="">
                                    </div></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Lanzamiento del modelo de razonamiento de UC Berkeley</h2><p class='mt-6'>El reconocido laboratorio de inteligencia artificial de UC Berkeley ha lanzado un nuevo modelo de razonamiento totalmente abierto llamado <strong>Sky-T1-32B-Preview</strong>.</p><p class='mt-6'>Este modelo está diseñado específicamente para tareas de razonamiento y programación. Es notable su rendimiento, logrando un <strong>82.4%</strong> en el conjunto de datos Math500 y <strong>86.3%</strong> en LiveCodeBench-Easy.</p><p class='mt-6'>La disponibilidad de este modelo se presenta como una opción muy accesible, a un costo de solo <strong>$450</strong>.</p><p class='mt-6'>Además del modelo, se ha proporcionado todo el <strong>conjunto de datos de entrenamiento</strong>, el código y la propia infraestructura del modelo.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhMcK8SaAAEwrQN.jpg" alt="">
                                    </div>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2">https://x.com/LiorOnAI/status/1878876546066506157'>aquí</a>.</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Inteligencia Artificial y Consumo Energético</h2><p class='mt-6'>Recientemente, se ha discutido sobre el consumo energético de modelos de inteligencia artificial. Las referencias suelen basarse en una estimación del año 2020 sobre el modelo GPT-3. Sin embargo, algunos expertos sugieren que es necesario actualizar esta información para una mejor comprensión del impacto real.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhIB0gQWYAAJV_e.jpg" alt="">
                                    </div><p class='mt-6'>Además, se ha creado un modelo de aprendizaje automático para predecir la sensibilidad al dolor en humanos. Este modelo se basa en el conjunto de datos más grande hasta la fecha sobre respuestas de imagen por resonancia magnética relacionadas con el dolor. La obtención de estos datos fue aprobada por los comités de ética.</p>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="tl" dir="ltr">forbidden Ilya scaling laws alpha <a href="https://t.co/vaIzvzLXAa">https://t.co/vaIzvzLXAa</a></p>&mdash; Minh Nhat Nguyen (@menhguin) <a href="https://twitter.com/menhguin/status/1878569780363587652?ref_src=twsrc%5Etfw">January 12, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Efecto de la Tecnología en el Desarrollo Social</h2><p class='mt-6'>Se ha afirmado que Steve Jobs contribuyó significativamente a mejorar las condiciones de vida de cientos de millones de personas al impulsar innovaciones tecnológicas. La influencia de su trabajo se extiende a muchas áreas de la vida cotidiana.</p><p class='mt-6'>En algunos países en desarrollo, el uso de smartphones es considerablemente mayor que el uso de computadoras personales. Esto indica un cambio en la manera en que las personas acceden a la información y tecnología, afectando positivamente sus ingresos y calidad de vida.</p>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">In developing countries, smartphone usage is substantially higher than PC usage, and when u factor in the income effects of the internet ...</p>&mdash; Minh Nhat Nguyen (@menhguin) <a href="https://twitter.com/menhguin/status/1878578652708995278?ref_src=twsrc%5Etfw">January 12, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div><div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Steve Jobs probably lifted hundreds of millions of people of out of poverty, tbh.</p>&mdash; Minh Nhat Nguyen (@menhguin) <a href="https://twitter.com/menhguin/status/1878578588381003884?ref_src=twsrc%5Etfw">January 12, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Debates sobre Inmigración y Diversidad</h2><p class='mt-6'>Un tuit humorístico menciona un intercambio de ideas sobre la política de inmigración en Estados Unidos, sugiriendo de manera sarcástica que la inclusión de más personas altamente calificadas de otros países podría ser una solución para mejorar la situación del país. Esta conversación en redes sociales refleja la complejidad y diversidad de opiniones sobre el tema.</p>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">&quot;We did it. We resurrected LKY. Father, tell us: what should we do to fix America?&quot;<br>&quot;Ten billion H1B Indians.&quot;<br>&quot;What? B-but—&quot;<br>&quot;Forced race mixing of neighborhoods.&quot;<br>&quot;Father, no—&quot;<br>&quot;Arrest anyone who disagrees.&quot; <a href="https://t.co/HmVlADfUTb">https://t.co/HmVlADfUTb</a> <a href="https://t.co/VzDOBU3Qvk">pic.twitter.com/VzDOBU3Qvk</a></p>&mdash; zhil (@zhil_arf) <a href="https://twitter.com/zhil_arf/status/1878657144989577615?ref_src=twsrc%5Etfw">January 13, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Innovaciones en Seguridad de Imágenes</h2><p class='mt-6'>Un nuevo marco ha sido presentado para la detección de seguridad de imágenes que no requiere etiquetado humano. Este desarrollo promete mejorar la seguridad en plataformas que utilizan imágenes generadas o modificadas por inteligencia artificial. La capacidad de evaluar la seguridad de las imágenes de manera autónoma será fundamental en la era digital.</p>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Zero-shot image safety detection, no human labeling needed.<br><br>A framework that enables MLLMs to judge image safety without human labeling, using objectified rules and debiased token probability analysis.<br><br>-----<br><br>🤔 Original Problem:<br><br>→ Current image safety systems rely heavily on… <a href="https://t.co/6MpzY1BbwG">pic.twitter.com/6MpzY1BbwG</a></p>&mdash; Rohan Paul (@rohanpaul_ai) <a href="https://twitter.com/rohanpaul_ai/status/1878538344663220278?ref_src=twsrc%5Etfw">January 12, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Novedades en Modelos de Inteligencia Artificial</h2><p class='mt-6'>SANA, un modelo de generación de imágenes de NVIDIA, ahora está bajo la licencia Apache 2.0. Esta herramienta permite crear imágenes de alta definición de hasta 4096 × 4096 píxeles con una velocidad impresionante. Su versión más pequeña, Sana-0.6B, es comparable con modelos mucho más grandes, siendo 20 veces más pequeña y más de 100 veces más rápida. Con un procesador gráfico de 16GB, se puede generar una imagen en menos de un segundo.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhJlDvta8AAloJF.jpg" alt="">
                                    </div><p class='mt-6'>NVIDIA también está desarrollando una colaboración con Stability AI para crear un nuevo modelo de inteligencia artificial que generará activos 3D a partir de imágenes simples. Esta integración encantará a los desarrolladores de contenido en 3D por facilitar el proceso de creación.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhJoJIFaEAAlZRg.jpg" alt="">
                                    </div><p class='mt-6'>Ultravox, un modelo de lenguaje multimodal que procesa tanto texto como voz, logra una tasa de respuesta rápida, procesando audio y emitiendo texto en tiempo real. Este modelo ha demostrado ser eficiente al emitir texto a una tasa aproximada de 60 tokens por segundo utilizando un modelo avanzado.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhKotMyXsAALpj1.jpg" alt="">
                                    </div></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Nuevas Funcionalidades en Gradio</h2><p class='mt-6'>Gradio ha implementado nuevas funcionalidades que incluyen la posibilidad de explorar SVFR, un marco para la restauración de video facial que permite restauraciones ciegas, colorización e incrustación de imágenes. Esta herramienta combina múltiples funciones en un solo sistema, lo que facilita el proceso de mejora de videos.</p><video controls class="w-full rounded-lg mb-4 mt-6">
                                        <source src="https://video.twimg.com/ext_tw_video/1878686573883281408/pu/vid/avc1/1024x512/lzb97HvNW2ubAhcR.mp4?tag=12" type="video/mp4">
                                        Tu navegador no soporta la reproducción de este video.
                                    </video><p class='mt-6'>Además, se destaca el uso de herramientas como langchain que ahora forman parte de ai-gradio, optimizando la interacción de desarrollo con modelos de aprendizaje automático.</p><p class='mt-6'>Aprovecha el nuevo agente de selección de navegador, que permite una integración fluida a través de aplicaciones Gradio. Esto mejora aún más la experiencia de desarrollo al usar Gradio.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhKBbDbXAAAA6Ps.jpg" alt="">
                                    </div></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Novedades de Veo 2</h2><p class='mt-6'>Veo 2 ha sido descrito como <strong>PURO FUEGO</strong> por usuarios que han tenido la oportunidad de probar su tecnología. Una creación generada en esta plataforma incluyó un <em>pequeño monstruo rosa</em> estilizado como rapero, realizando acrobacias como un <em>kickflip</em> en una patineta, mientras el líquido que lo compone se mueve dinámicamente.</p><video controls class="w-full rounded-lg mb-4 mt-6">
                                        <source src="https://video.twimg.com/ext_tw_video/1878758832018464769/pu/vid/avc1/1280x720/l9tL2MzJsVAkXUA-.mp4?tag=12" type="video/mp4">
                                        Tu navegador no soporta la reproducción de este video.
                                    </video><p class='mt-6'>Otro video exhibe un creativo <strong>pangolín</strong> surfeando una ola. Esta escena captura los movimientos ágiles del pangolín y la vibra <em>jugadora</em> del entorno, lo que muestra la capacidad creativa de la inteligencia artificial utilizada en Veo 2.</p><video controls class="w-full rounded-lg mb-4 mt-6">
                                        <source src="https://video.twimg.com/ext_tw_video/1878778963079663616/pu/vid/avc1/1280x720/WwSJvy_3d-LEhXyS.mp4?tag=12" type="video/mp4">
                                        Tu navegador no soporta la reproducción de este video.
                                    </video><p class='mt-6'>Algunos usuarios han destacado que la calidad de producción generada por Veo 2 es asombrosa y ha cambiado la forma de ver el <strong>cine</strong>, al permitir la generación de contenido a partir de simples instrucciones o <em>prompts</em> sin necesidad de habilidades avanzadas en producción.</p></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Creatividad y Accesibilidad</h2><p class='mt-6'>La accesibilidad de Veo 2 y su funcionalidad podría dar lugar a un cambio de paradigma en cómo se crea el contenido audiovisual. La posibilidad de generar un <em>largometraje</em> a partir de descripciones simples ha sido un punto de interés para los usuarios, quien se preguntan qué futuro podrán imaginar con este tipo de herramientas.</p><video controls class="w-full rounded-lg mb-4 mt-6">
                                        <source src="https://video.twimg.com/ext_tw_video/1878806317264928768/pu/vid/avc1/1280x720/rPkKsylApWOZaazl.mp4?tag=12" type="video/mp4">
                                        Tu navegador no soporta la reproducción de este video.
                                    </video><p class='mt-6'>Además, uno de los usuarios comentó que es como haber saltado 12 meses al futuro en cuanto a tecnología, lo que refleja lo innovador que es este sistema.</p><video controls class="w-full rounded-lg mb-4 mt-6">
                                        <source src="https://video.twimg.com/ext_tw_video/1878575682986389505/pu/vid/avc1/1280x720/dhyC_vVVNRIoJjUt.mp4?tag=12" type="video/mp4">
                                        Tu navegador no soporta la reproducción de este video.
                                    </video><p class='mt-6'>Un ejemplo más de Veo 2 es una escena de una mujer aventurera, similar a <strong>Lara Croft</strong>, montando en un carrito a gran velocidad por una mina oscura. Esto muestra la versatilidad y las posibilidades creativas del programa, lo que ha impresionado a muchos.</p></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Casos de uso para agentes multimodales</h2><p class='mt-6'>Se están planteando preguntas serias sobre cómo construir agentes que manejen múltiples modalidades de información.</p><p class='mt-6'>Una reflexión importante es cómo se deberían pasar las imágenes durante el proceso. Es clave saber si hay casos en los que es necesario proporcionar imágenes en pasos intermedios o si se deben entregar desde el inicio del proceso.</p></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Soporte en el Cookbook de Hugging Face</h2><p class='mt-6'>Gracias al apoyo de la comunidad, el Cookbook de Hugging Face ahora está disponible en turco. Celebramos esta adición que facilitará el acceso a recursos en este idioma.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhLo01HX0AAW6TK.jpg'/>" alt="">
                                    </div></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Avances en modelos multimodales</h2><p class='mt-6'>Se ha anunciado un nuevo modelo de recuperación multimodal llamado vdr-2b-multi-v1 por parte de llama_index.</p><p class='mt-6'>Este modelo utiliza un 70% menos de tokens de imagen mientras supera a otros modelos basados en dse-qwen2. Además, ofrece una inferencia tres veces más rápida con menos VRAM y tiene la capacidad de realizar recuperaciones cruzadas en diferentes idiomas.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhKu6AtXAAAi8qG.png'/>" alt="">
                                    </div></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Más información disponible</h2><p class='mt-6'>Para aquellos interesados en profundizar en los temas tratados, se pueden consultar artículos adicionales y demostraciones relacionadas, accesibles a través de su respectivo blog y otras publicaciones.</p><p class='mt-6'>Últimas novedades sobre modelos y conjuntos de datos también pueden ser consultadas directamente desde plataformas como Hugging Face.</p></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Lanzamiento del modelo Helium-1</h2><p class='mt-6'>El modelo Helium-1 Preview ha sido lanzado por <a href="https://x.com/kyutai_labs" class="text-blue-500 underline">@kyutai_labs</a>. Se trata de un modelo de lenguaje base con 2 mil millones de parámetros, diseñado para dispositivos móviles y de borde. Esto lo hace muy accesible, ya que puede funcionar con menos de 1GB de memoria de video.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhMUBecW4AANQhs.jpg'>" alt="">
                                    </div><p class='mt-6'>Este modelo es de código abierto y multilingüe. Supera o es comparable a otros modelos como Qwen 2.5 1.5B, Owen 1.5B, Gemma 2B y Llama 3B. Ha sido entrenado con 2.5 billones de tokens y tiene un tamaño de contexto de 4096.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhMNetGWoAATXbO.jpg'>" alt="">
                                    </div></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Actualización sobre la línea de tiempo de IA 2025</h2><p class='mt-6'>La línea de tiempo para el año 2025 en el ámbito de la inteligencia artificial ha mostrado hasta ahora interesantes lanzamientos de laboratorios abiertos, a pesar de la falta de anuncios significativos de laboratorios cerrados como Anthropic, OpenAI y Gemini.</p><p class='mt-6'>Entre los lanzamientos destacados están OpenBMB con Eurus 2 de 7B, Nvidia Cosmos y Moondream 2, marcando un escenario prometedor para el avance de la inteligencia artificial en el próximo año.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhHy-5SWAAAd_QM.jpg'>" alt="">
                                    </div><p class='mt-6'>El evento ha sido motivo de expectación y se anticipa que este mes de enero de 2025 será significativo para la comunidad de IA.</p><video controls class="w-full rounded-lg mb-4 mt-6">
                                        <source src="https://video.twimg.com/ext_tw_video/1878547975821012992/pu/vid/avc1/1112x720/wSEqoRqQc5qBtd1J.mp4?tag=12'></video>" type="video/mp4">
                                        Tu navegador no soporta la reproducción de este video.
                                    </video></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Interacción en la comunidad tecnológica</h2><p class='mt-6'>La comunidad está activa y se hacen preguntas sobre diferentes proyectos. Preguntas como si los nuevos modelos pueden correr en Google Colab T4 están en el aire.</p><p class='mt-6'>Las interacciones en redes sociales muestran un interés por las novedades y avances en inteligencia artificial, así como sus aplicaciones y requerimientos técnicos.</p></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Comienzo de juegos de ajuste fino</h2><p class='mt-6'>La comunidad ha expresado emoción por el inicio de las competiciones de ajuste fino de los nuevos modelos, lo que sugiere un ambiente de innovación y competencia en el desarrollo de inteligencia artificial.</p></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Expectativas de lanzamientos futuros</h2><p class='mt-6'>La expectativa de futuros lanzamientos por parte de laboratorios abiertos ha sido bien recibida. La comunidad sigue atenta a nuevos anuncios y desarrollos en el campo de la IA.</p></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Reflexiones sobre el Futuro</h2><p class='mt-6'>Un usuario ha compartido un pensamiento sobre el año 2025, calificándolo de 'una locura'. Esta afirmación insinúa que se anticipan cambios o situaciones sorprendentes en un futuro cercano.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhMdUflWEAA2Rgs.jpg"" alt="">
                                    </div><p class='mt-6'>La declaración invita a la reflexión sobre cómo el tiempo y los avances pueden transformar nuestras vidas. Lo que parece descabellado hoy podría ser una realidad cotidiana en solo unos años.</p>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">in 2025 this is a bit crazy imo <a href="https://t.co/cSpFmRLf5w">pic.twitter.com/cSpFmRLf5w</a></p>&mdash; Julien Chaumond (@julien_c) <a href="https://twitter.com/julien_c/status/1878877780118745175?ref_src=twsrc%5Etfw">January 13, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Innovaciones en Texto a Voz y Aprendizaje Automático</h2><p class='mt-6'>Recientemente, se ha destacado la disponibilidad de herramientas de código abierto para la síntesis de voz (TTS) que ofrecen inferencias rápidas. Esta novedad ha generado expectativas sobre qué aplicaciones innovadoras se podrían desarrollar con esta tecnología.</p><p class='mt-6'>Además, se ha publicado un nuevo artículo en el blog de Hugging Face, donde se explora el tema de las dimensiones tensoriales y su propagación, fundamental en el contexto del aprendizaje automático.</p></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Nuevas mejoras en SetFit v1.1.1</h2><p class='mt-6'>Se ha lanzado SetFit v1.1.1, que permite afinar modelos de clasificación extremadamente eficientes en CPU y GPU. Esta versión se basa en el modelo de incrustación ModernBERT de Nomic AI.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhK43CaXsAAXUjD.jpg" alt="">
                                    </div><p class='mt-6'>Para más detalles sobre esta actualización, consulta el enlace correspondiente.</p>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">I&#39;ve just published SetFit v1.1.1, allowing finetuning extremely efficient classification models on CPU &amp; GPU based on Nomic AI their ModernBERT embedding model. <br><br>Details in 🧵 <a href="https://t.co/40a9Qg0cwk">pic.twitter.com/40a9Qg0cwk</a></p>&mdash; tomaarsen (@tomaarsen) <a href="https://twitter.com/tomaarsen/status/1878767886204096914?ref_src=twsrc%5Etfw">January 13, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Actualizaciones importantes</h2><p class='mt-6'>La nueva actualización incluye compatibilidad con la versión 4.45.2 y superior de Transformers, donde usar la versión 4.48.0 añade soporte para la arquitectura ModernBERT.</p><p class='mt-6'>Se ha corregido un problema donde no se ignoraba `report_to="none"` en los argumentos de entrenamiento. Ahora se deshabilitan correctamente los callbacks automáticos si así se desea.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhK5JcsWYAA-OTT.png" alt="">
                                    </div><p class='mt-6'>Más información sobre estas funcionalidades se encuentra aquí.</p>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Updates:<br>- Compatibility with Transformers v4.45.2+ is added. Using v4.48.0 adds ModernBERT architecture support as well!<br>- Prevent `report_to=&quot;none&quot;` from being ignored in the TrainingArguments. This should now correctly disable automatic callbacks if you want.<br><br>🧵 <a href="https://t.co/0sdoH4EV9d">pic.twitter.com/0sdoH4EV9d</a></p>&mdash; tomaarsen (@tomaarsen) <a href="https://twitter.com/tomaarsen/status/1878767889785979109?ref_src=twsrc%5Etfw">January 13, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Proyectos y aplicaciones de SetFit</h2><p class='mt-6'>Los pequeños clasificador pueden ser muy valiosos, por ejemplo, para el enrutamiento de modelos de lenguaje de gran tamaño. Son sencillos de entrenar y no requieren grandes cantidades de datos.</p><p class='mt-6'>Consulta el proyecto en el siguiente enlace y revisa el script de entrenamiento con ModernBERT en las notas de la versión.</p>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Check out the project here: <a href="https://t.co/pvlRg3xPWv">https://t.co/pvlRg3xPWv</a><br><br>Or have a look at the training script with ModernBERT in the release notes: <a href="https://t.co/Rer6FZo04h">https://t.co/Rer6FZo04h</a><br><br>Small classifiers can be very valuable, e.g. for LLM routing. They&#39;re simple to train, and don&#39;t require much data either.</p>&mdash; tomaarsen (@tomaarsen) <a href="https://twitter.com/tomaarsen/status/1878767892256457141?ref_src=twsrc%5Etfw">January 13, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Contenido multimedia de Niels Rogge</h2><p class='mt-6'>Niels Rogge ha compartido sus objetivos para 2025, que incluyen la creación de más contenido en YouTube. En su video de hoy, repasa todas las nuevas funciones de Hugging Face.</p><p class='mt-6'>Empodera tu aprendizaje con este contenido útil.</p>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">One of my goals in 2025 is making more <a href="https://twitter.com/YouTube?ref_src=twsrc%5Etfw">@YouTube</a> content<br><br>In today&#39;s video I go over ALL of the new features in <a href="https://twitter.com/huggingface?ref_src=twsrc%5Etfw">@huggingface</a> Transformers v4.48: ModernBERT, ColPali, ViTPose, and more!<br><br>I also accidentally explain how a Transformer works to make you understand ModernBERT :) <a href="https://t.co/eYY7mbVWlr">pic.twitter.com/eYY7mbVWlr</a></p>&mdash; Niels Rogge (@NielsRogge) <a href="https://twitter.com/NielsRogge/status/1878115664654635490?ref_src=twsrc%5Etfw">January 11, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Sorpresa con el Panel de Conocimiento de Google</h2><p class='mt-6'>Un usuario se mostró gratamente sorprendido por la aparición de su panel de conocimiento en Google.</p><p class='mt-6'>El usuario expresó que no esperaba que esto sucediera tan pronto, ya que era uno de sus deseos desde hacía unos meses.</p><p class='mt-6'>El descubrimiento se produjo cuando buscó su nombre en la plataforma y encontró el panel.</p><p class='mt-6'>Aunque el nombre se mostró de manera incorrecta en cirílico serbio, el usuario planea corregirlo una vez que sea verificado.</p><p class='mt-6'>El panel de conocimiento es una herramienta que ofrece información rápida y relevante sobre personas, lugares y cosas relacionadas. Este tipo de recursos se generan a partir de datos recopilados por Google. Continuamente, los usuarios pueden contribuir a la mejora de esta información.</p><p class='mt-6'>A continuación, se presenta una imagen del panel de conocimiento.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhMLnxxXYAEbMnE.png" alt="">
                                    </div></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">**Debate sobre IA en la educación**</h2><p class='mt-6'>La discusión sobre la prohibición del uso de inteligencia artificial en las aulas está en auge. Algunos educadores argumentan que es importante prohibir el uso de IA en ciertas asignaturas donde los estudiantes deben desarrollar habilidades que compiten con la inteligencia artificial. La paralela en el uso de calculadoras es un ejemplo conocido: su uso se ha permitido lentamente en matemáticas tras evaluar su impacto en el aprendizaje.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/Ek-08K7W0AEZodn.jpg'>" alt="">
                                    </div><p class='mt-6'>Sin embargo, también se destaca que el aprendizaje efectivo requiere esfuerzo y compromiso activo, un proceso que muchos estudiantes encuentran desagradable en diversas clases. A menudo, el trabajo duro puede llevar a la sensación de que están aprendiendo menos, pero es esencial para el aprendizaje real. Una cita relevante señala que los instructores deben convencer a los alumnos de los beneficios de trabajar arduamente, ya que la dificultad inherente a este proceso puede afectar negativamente su aprendizaje.</p><p class='mt-6'>La necesidad de más tareas en clase y ejercicios de discusión surge en unión con quienes deseen prohibir el uso de IA, mientras que quienes buscan aprovecharla tendrán que asegurar que no comprometa los objetivos de aprendizaje.</p><p class='mt-6'>Entre las controversias, se menciona que los detectores de IA no funcionan adecuadamente, lo que complica aún más la discusión.</p>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Learning requires effort and active engagement, which most people find unpleasant for at least some classes. Paradoxically, working hard can make students feel like they are learning less. You can make people work hard with or without AI, but there is no way to skip the effort. <a href="https://t.co/vQMzLTy6Gj">https://t.co/vQMzLTy6Gj</a></p>&mdash; Ethan Mollick (@emollick) <a href="https://twitter.com/emollick/status/1878825523788574880?ref_src=twsrc%5Etfw">January 13, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div><div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Want to ban AI? You will need more in-class assignments, discussions and tests for assessment.<br><br>Want to allow AI? Make sure it doesn’t compromise your learning objectives.<br><br>Want to require AI? You will need to build and test prompts &amp; approaches and then explain and assign them.</p>&mdash; Ethan Mollick (@emollick) <a href="https://twitter.com/emollick/status/1878822589285757049?ref_src=twsrc%5Etfw">January 13, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">**Energía y eficiencia de IA**</h2><p class='mt-6'>La discusión sobre el impacto ambiental de la inteligencia artificial sigue generando confusión y malentendidos. Existe un enfoque común en una estimación anterior del consumo de energía de GPT-3, pero investigaciones recientes han medido el consumo de energía del modelo Llama 65B de 3 a 4 julios por token decodificado, comparando así el consumo de energía con el de una hora de transmisión en Netflix que equivale a 70 a 90 mil tokens del modelo citado.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhI9hVyWYAAz14Z.jpg'>" alt="">
                                    </div><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhI9ipvWcAA79sV.png'>" alt="">
                                    </div><p class='mt-6'>Estos números resaltan la continua necesidad de datos actualizados sobre el consumo energético de los modelos de IA, lo que sugiere que los laboratorios debería publicar más información sobre el impacto ambiental de sus tecnologías.</p><p class='mt-6'>La charla se extiende a la posible mejora de la eficiencia, sugiriendo que las nuevas versiones podrían reducir el consumo de energía a .4 julios por token en el modelo Llama 3.3 de 70B.</p>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">I also agree with <a href="https://twitter.com/simonw?ref_src=twsrc%5Etfw">@simonw</a> that the labs should be clearly publishing this data, since environmental impact remains one of the most common, confusing and misleading debates about the impact of AI.</p>&mdash; Ethan Mollick (@emollick) <a href="https://twitter.com/emollick/status/1878808499922292964?ref_src=twsrc%5Etfw">January 13, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div><div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">So here is a claim that efficiency gains might already 10x over the paper, down to .4 joule/token on Llama 3.3 70B on a H100 node. <a href="https://t.co/708NvfZFMI">https://t.co/708NvfZFMI</a></p>&mdash; Ethan Mollick (@emollick) <a href="https://twitter.com/emollick/status/1878693307360137649?ref_src=twsrc%5Etfw">January 13, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">**Creatividad y contenido generado por IA**</h2><p class='mt-6'>Un hilo destaca la capacidad creativa de modelos de IA. Uno de los mensajes menciona una sugerencia divertida proporcionada por Claude: Master and Command Gander, relacionado con juegos de palabras. Las interacciones creativas están abriendo nuevos caminos en la generación de contenido, desde relatos hasta experimentos en la música y el cine.</p><p class='mt-6'>Una reciente experiencia implicó usar la IA Claude para transformar estrofas del poema La Dama de Shalott en una secuencia visual, constituyendo un intento interesante de combinar poesía y video.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhIy-6kWQAADAE7.png'>" alt="">
                                    </div><video controls class="w-full rounded-lg mb-4 mt-6">
                                        <source src="https://video.twimg.com/ext_tw_video/1878602293039243264/pu/vid/avc1/1280x720/ESCLBGPhlUPMYykK.mp4?tag=12" type="video/mp4">
                                        Tu navegador no soporta la reproducción de este video.
                                    </video><p class='mt-6'>Y otro video relacionado se puede observar aquí:</p><video controls class="w-full rounded-lg mb-4 mt-6">
                                        <source src="https://video.twimg.com/ext_tw_video/1878325593894162432/pu/vid/avc1/1280x720/k4ioUJ3tiMMiPxqr.mp4?tag=12" type="video/mp4">
                                        Tu navegador no soporta la reproducción de este video.
                                    </video><p class='mt-6'>En resumen, estos desarrollos subrayan el potencial de la inteligencia artificial en la creación y en la solución de las problemáticas contemporáneas en distintos ámbito.</p></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Reflexiones sobre AI y sostenibilidad</h2><p class='mt-6'>Una de las recientes discusiones gira en torno a la sostenibilidad de la inteligencia artificial en comparación con los escritores humanos. Según Roope Rainisto, los sistemas de inteligencia artificial emiten entre 130 y 1500 veces menos dióxido de carbono equivalente por página de texto generada que los escritores humanos. Además, los sistemas de ilustración de inteligencia artificial generan entre 310 y 2900 veces menos dióxido de carbono equivalente por imagen.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhIeDiJXgAACvS-.jpg" alt="">
                                    </div><p class='mt-6'>Credibilidad en la inteligencia artificial también se ha abordado como un tema importante en la conversación actual.</p>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">If you believe in climate change you shouldn&#39;t be hiring human workers. <a href="https://t.co/3jRzg8Y3In">https://t.co/3jRzg8Y3In</a></p>&mdash; Mike Taylor (@hammer_mt) <a href="https://twitter.com/hammer_mt/status/1878767335265505400?ref_src=twsrc%5Etfw">January 13, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Casos de abuso en Rotherham</h2><p class='mt-6'>En un tweet de Sam Ashworth-Hayes, se expusieron preocupantes obstáculos que enfrentaron las personas en Rotherham que investigaron casos de abuso. Se hicieron alegaciones sobre documentos que desaparecieron de edificios cerrados, declaraciones amenazantes hechas por la policía y computadoras con datos que también desaparecieron.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhLaYe5WEAAx1kN.jpg" alt="">
                                    </div><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhLaYg4XUAAXG5A.jpg" alt="">
                                    </div><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhLaY7DWUAAFu-k.jpg" alt="">
                                    </div><p class='mt-6'>Esta situación ha llevado a muchos a cuestionar la veracidad de las representaciones de la serie 'Line of Duty'.</p>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">I always thought line of duty was too farfetched <a href="https://t.co/Agbf8ZkC8B">https://t.co/Agbf8ZkC8B</a></p>&mdash; Mike Taylor (@hammer_mt) <a href="https://twitter.com/hammer_mt/status/1878839156228731173?ref_src=twsrc%5Etfw">January 13, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Pensamientos sobre el enfoque humano en la creación</h2><p class='mt-6'>Dan Shipper resaltó la evolución de nuestra forma de pensar, pasando de un enfoque paso a paso a un enfoque persona por persona en la creación. Se destaca la importancia de reflexionar sobre estas transformaciones en nuestra comprensión del proceso creativo.</p>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">We&#39;ve gone from thinking step-by-step to thinking person-by-person. <a href="https://t.co/hwf0jsvWh4">https://t.co/hwf0jsvWh4</a></p>&mdash; Mike Taylor (@hammer_mt) <a href="https://twitter.com/hammer_mt/status/1878852758687883360?ref_src=twsrc%5Etfw">January 13, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Interacciones e inicios de conversación</h2><p class='mt-6'>Un reciente retweet hizo eco al trabajo de <a href="https://x.com/hammer_mt" class="text-blue-500 underline">@hammer_mt</a>, reforzando el valor que se otorga a estas discusiones y reflexiones sobre la inteligencia artificial y los desafíos sociales actuales.</p>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">We knew that!<br>Still, great work <a href="https://twitter.com/hammer_mt?ref_src=twsrc%5Etfw">@hammer_mt</a></p>&mdash; Synthetic Users (@syntheticusers) <a href="https://twitter.com/syntheticusers/status/1878865162347958325?ref_src=twsrc%5Etfw">January 13, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Cuestionamientos sobre el contenido técnico</h2><p class='mt-6'>Desde el ámbito de la ingeniería, se presentó una pregunta simple pero intrigante sobre si un individuo puede levantarse usando una cuerda de polea. Este tipo de cuestiones revela un interés en explorar conceptos básicos de la física y la mecánica.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhHJAs7W4AEvmcN.jpg" alt="">
                                    </div>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">This is fairly obvious, it&#39;s just a pullup <a href="https://t.co/IQdzo3yQKD">https://t.co/IQdzo3yQKD</a></p>&mdash; Mike Taylor (@hammer_mt) <a href="https://twitter.com/hammer_mt/status/1878845553477550461?ref_src=twsrc%5Etfw">January 13, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Desarrollo en Modelos de Lenguaje y Aprendizaje Automático</h2><p class='mt-6'>Un usuario en redes sociales compartió un video sobre un modelo de lenguaje funcionando en una consola Xbox 360. Esta consola cuenta con un procesador Xenon de 3.2 GHz y memoria unificada de 512 MB. El modelo se basa en el trabajo de Andrej Karpathy y su código llama2. Está diseñado para demostrar que es posible ejecutar modelos sofisticados en hardware limitado.</p><p class='mt-6'>MinishLab ha realizado un esfuerzo significativo para mejorar la eficiencia de los embeddings utilizando Semhash. Esta técnica se centra en la deduplicación semántica, permitiendo filtrar datasets para obtener mejores modelos, además de reducir el tiempo de entrenamiento y los recursos computacionales necesarios. Este avance promete optimizar el desarrollo de modelos de inteligencia artificial.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhLl7D2XEAAVprC.jpg" alt="">
                                    </div><p class='mt-6'>SCRIT y Contrastive Critic están trabajando en la creación de un dataset crítico de buena calidad, añadiendo razonamientos sintéticos a partir de respuestas correctas conocidas. Se propone que este método puede ofrecer insights interesantes y es un área que vale la pena explorar en más profundidad.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhLM0bzXoAAD2GP.jpg" alt="">
                                    </div></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Desarrollo y Aplicaciones de la Inteligencia Artificial</h2><p class='mt-6'>Un nuevo demo de uso de IA abierto fue compartido por <a href="https://x.com/jamesmurdza" class="text-blue-500 underline">@jamesmurdza</a>. Este sistema utiliza tres modelos de lenguaje avanzados. Esto marca un avance significativo en el uso abierto de tecnologías de inteligencia artificial.</p>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Listen to <a href="https://twitter.com/jamesmurdza?ref_src=twsrc%5Etfw">@jamesmurdza</a>&#39;s demo of a 100% open-source Computer Use.<br><br>The agent is using 3 different LLMs:<br>🔸Llama 3.2 (<a href="https://twitter.com/AIatMeta?ref_src=twsrc%5Etfw">@AIatMeta</a>)<br>🔸Llama 3.3<br>🔸OS-Atlas (<a href="https://twitter.com/Alibaba_Qwen?ref_src=twsrc%5Etfw">@Alibaba_Qwen</a>, <a href="https://twitter.com/JustinLin610?ref_src=twsrc%5Etfw">@JustinLin610</a>)<br><br>This example is using <a href="https://twitter.com/e2b_dev?ref_src=twsrc%5Etfw">@e2b_dev</a>&#39;s Desktop Sandbox as a virtual computer.  It&#39;s completely… <a href="https://t.co/2tAlJVs75j">pic.twitter.com/2tAlJVs75j</a></p>&mdash; Tereza Tizkova (@tereza_tizkova) <a href="https://twitter.com/tereza_tizkova/status/1878834392891838556?ref_src=twsrc%5Etfw">January 13, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Tendencias en Modelos de Lenguaje y Procesamiento de Datos</h2><p class='mt-6'>La empresa Meta ha introducido recientemente los Modelos de Concepto a Gran Escala, lo cual promete transformar las aplicaciones de inteligencia artificial. Esta innovación podría abrir nuevas vías para el procesamiento de datos y comprensión contextual en IA.</p><p class='mt-6'>El uso de eBPF (Berkeley Packet Filter extendido) para capturar tráfico local por nombre de proceso se presenta como una poderosa herramienta para la seguridad de datos. Este avance podría facilitar la monitorización de la privacidad y seguridad en redes.</p>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">The Future of AI<br><br>Explores the potential and applications of Large Concept Models which was  recently introduced by Meta.<a href="https://t.co/84LpkNqXkn">https://t.co/84LpkNqXkn</a> <a href="https://t.co/PHnKofvhKe">pic.twitter.com/PHnKofvhKe</a></p>&mdash; elvis (@omarsar0) <a href="https://twitter.com/omarsar0/status/1878822820177985879?ref_src=twsrc%5Etfw">January 13, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div><div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">This is very powerful<br><br>using eBPF to capture local traffic by process name<br><br>I think mitmproxy is turning to be best cross platform capturing tool. <br><br>I’m glad I chose it for my courses <a href="https://t.co/IEMii23KNC">https://t.co/IEMii23KNC</a> <a href="https://t.co/OdJFCjqWOG">pic.twitter.com/OdJFCjqWOG</a></p>&mdash; Hussein Nasser (@hnasr) <a href="https://twitter.com/hnasr/status/1878472677910045131?ref_src=twsrc%5Etfw">January 12, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Desarrollo de Sistemas y Modelos Avanzados</h2><p class='mt-6'>Se ha presentado Kokoro-82M, un sistema que genera discursos en un tiempo reducido, mostrando avances en síntesis de voz y generación de audio en IA. Esto puede ser un gran recurso para desarrolladores de tecnologías de voz.</p><p class='mt-6'>Se discutió la importancia de SemHash, una nueva herramienta de deduplicación semántica, la cual es crítica durante el entrenamiento de modelos de lenguaje. Esta herramienta promete mejorar la calidad de los datos utilizados en el entrenamiento de IA.</p>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Listen to Kokoro-82M...<br><br>2m25s of speech generated in 4.5s on a T4<a href="https://t.co/hXCtDxFSUA">https://t.co/hXCtDxFSUA</a><a href="https://t.co/53BkEcOpum">https://t.co/53BkEcOpum</a><br><br>So graceful, so precise. <a href="https://t.co/8bd86kWFwV">pic.twitter.com/8bd86kWFwV</a></p>&mdash; fofr (@fofrAI) <a href="https://twitter.com/fofrAI/status/1878807358887154044?ref_src=twsrc%5Etfw">January 13, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div><div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Data Leakage and deduplication are critical when training LLMs! SemHash is a new, blazingly fast semantic text deduplication library that combines Model2Vec embeddings with ANN-based similarity search through Vicinity, making it possible to deduplicate millions of records in… <a href="https://t.co/tXK5G5ec6y">pic.twitter.com/tXK5G5ec6y</a></p>&mdash; Philipp Schmid (@_philschmid) <a href="https://twitter.com/_philschmid/status/1878743789155516565?ref_src=twsrc%5Etfw">January 13, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Innovaciones en Frameworks de Inteligencia Artificial</h2><p class='mt-6'>SCRIT ha sido introducido como un marco auto-evolutivo para la crítica de Modelos de Lenguaje a Gran Escala. Este sistema busca mejorar la supervisión y críticas hacia los modelos, permitiendo un ciclo de retroalimentación más eficiente.</p><p class='mt-6'>La implementación de ReAct (Razonamiento y Acción) por Quantalogic ha sido destacada como un enfoque fascinante para abordar tareas complejas en inteligencia artificial. Este método promete revolucionar la forma en la que se diseñan y ejecutan las interacciones con IA.</p>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Introducing SCRIT: A Self-Evolving Framework for Large Language Model Critique ...<br><br>Have you ever wondered about the challenges faced by Large Language Models (LLMs) when it comes to effective critique and oversight? <br><br>Current methods often rely heavily on human input or stronger… <a href="https://t.co/ouMMv5QDkk">pic.twitter.com/ouMMv5QDkk</a></p>&mdash; Raphael Mansuy 🍵 (@raphaelmansuy) <a href="https://twitter.com/raphaelmansuy/status/1878654552628711724?ref_src=twsrc%5Etfw">January 13, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div><div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">🤔 Ever wondered how AI agents can write complete tutorials in a single prompt?<br><br>Quantalogic&#39;s implementation of ReAct (Reasoning &amp; Acting) Agents - is a fascinating piece of engineering that transforms how we handle complex AI tasks.<br><br>The magic lies in its state machine… <a href="https://t.co/AQuhnjlr5W">pic.twitter.com/AQuhnjlr5W</a></p>&mdash; Raphael Mansuy 🍵 (@raphaelmansuy) <a href="https://twitter.com/raphaelmansuy/status/1878704720312983775?ref_src=twsrc%5Etfw">January 13, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Novedades y Actualizaciones de Herramientas</h2><p class='mt-6'>Quantalogic lanzó una nueva versión de su herramienta, abordando un bug relacionado con git_ls que afectaba la ejecución de ciertas herramientas. Esto mejorará la funcionalidad y confiabilidad en el uso de su herramienta.</p><p class='mt-6'>Se añadió soporte para plantillas Jinja2, aumentando la capacidad de manejo de variables y ejecución de propiedades en herramientas de análisis y desarrollo, mejorando su versatilidad y funcionalidad.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhJF4xTXIAAJWYc.jpg" alt="">
                                    </div><p class='mt-6'><a href="https://x.com/contextualize" class="text-blue-500 underline">@contextualize</a></p><p class='mt-6'>{bueno}, satinado: {Inteligencia AI, códigos abiertos, IA, tecnologías emergentes}, categórico: [{ reacción, propuesta, contextualización}, { contexto, crecimiento, significación}]}  ```.LabelControl-Node { Sugerido:   *(por primera vez, no hace falta para aprovisionar detenimiento, pero se debe enfatizar: debemos continuar incrementando nuestras investigaciones y prácticas en este campo)* Se lanza esta reflexión previa a la finalización.  *(reitero la importancia de que continúen formándose en tecnología y prácticas correspondientes en el tema que se ha presentado*)*  *(también invitar a ser parte activa dentro del ciclo de evolución y reflexión hacia estos términos de avance)*! En general se sugiere a las comunidades integrarse para fomentar una visión común que promueva interactividad, esa es una experiencia enriquecedora en sí misma.  De esta forma se hace un llamado a la comunidad a avanzar juntos en la conversación sobre la inteligencia artificial y su impacto en la vida cotidiana.  Promoviendo una cultura basada en el conocimiento mutuo y la innovación eficaz.</p>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">New release of Quantalogic<br><br>[0.2.21] (2025-01-13)<br>- Fix a git_ls bug that caused that block the tool execution on certain directories<br>- By default create a basic agent instead of a coding agent<a href="https://t.co/saAwTjhcNs">https://t.co/saAwTjhcNs</a></p>&mdash; Raphael Mansuy 🍵 (@raphaelmansuy) <a href="https://twitter.com/raphaelmansuy/status/1878653675356467480?ref_src=twsrc%5Etfw">January 13, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div><div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr"><a href="https://t.co/saAwTjhcNs">https://t.co/saAwTjhcNs</a><br><br>New version v 0.2.20<br><br>- Added tool property injection precedence at runtime using tool.get_injectable_properties_in_execution()<br>- Added Jinja2 template support with enhanced variable handling<br>- Implemented pagination support for search_definition_names…</p>&mdash; Raphael Mansuy 🍵 (@raphaelmansuy) <a href="https://twitter.com/raphaelmansuy/status/1878636206021550201?ref_src=twsrc%5Etfw">January 13, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">La Limitación en el Razonamiento de la Inteligencia Artificial</h2><p class='mt-6'>La inteligencia artificial todavía no puede razonar como los humanos, a pesar de los esfuerzos por enseñarle. He trabajado con modelos más pequeños como Llama y Phi-4, utilizando un método llamado <strong>Chain of Thought Supervised Fine-tuning</strong> (CoT-SFT). Este enfoque busca que la inteligencia artificial aprenda a resolver problemas paso a paso, a través de ejemplos de pensamiento humano.</p><p class='mt-6'>Sin embargo, aunque este método muestra mejoras, no es una solución mágica. A menudo, los modelos confunden sus instintos iniciales con la respuesta correcta y justifican sus elecciones en lugar de explorar todas las opciones. Esto se debe a que los modelos, incluso los más completos, pueden tener dificultades para acceder a la información correcta en sus redes de parámetros, optando por la primera opción que se les presenta.</p><p class='mt-6'>Para mejorar el razonamiento, es fundamental que la inteligencia artificial considere múltiples perspectivas y aumente su tiempo de reflexión.</p></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Soluciones al Razonamiento Defectuoso</h2><p class='mt-6'>He realizado modificaciones en Llama, creando una versión mejorada denominada <strong>Llama 3.2 MedIT 3B o1</strong>. Esta nueva estructura tiene varios módulos de <em>pensadores</em> que trabajan simultáneamente, aumentando la capacidad de cálculo en el momento de la prueba (denominada <strong>Test-Time Compute</strong> o TTC).</p><p class='mt-6'>Los módulos de pensadores no solo trabajan de manera independiente, sino que comparan sus creencias internas para decidir cuál es la respuesta más confiable. Este enfoque fomenta un proceso de razonamiento más robusto, donde la inteligencia artificial evalúa diferentes líneas de pensamiento antes de decidir.</p></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Ejemplo Práctico en el Proceso de Aprendizaje</h2><p class='mt-6'>Por ejemplo, pedí al modelo que contara la letra 'R' en las palabras <strong>"strawberry"</strong> y <strong>"rover"</strong>. Este ejercicio desafía al modelo a ser preciso y no apresurarse a conclusiones.</p><p class='mt-6'>El objetivo es enseñar a la inteligencia artificial a no confiar en su primer impulso, sino a considerar diversas líneas de razonamiento y elegir la mejor, lo cual es un avance hacia modelos que realmente puedan razonar y resolver problemas más allá de imitar el pensamiento humano.</p></section>
    </main>

    <footer class="bg-blue-600 text-white text-center py-4">
        <p>&copy; 2025 Todos los derechos reservados. Reporte de Noticias - Inteligencia Artificial</p>
    </footer>

    <div id="popup" class="popup-overlay">
        <button class="close-btn" id="close-btn">X</button>
        <img id="popup-image" src="" alt="Imagen ampliada">
    </div>

    <script>
        // Elementos del DOM
        const thumbnails = document.querySelectorAll('.image-container img');
        const popup = document.getElementById('popup');
        const popupImage = document.getElementById('popup-image');
        const closeBtn = document.getElementById('close-btn');

        // Variables para el zoom
        let isZoomedIn = false;
        let isDragging = false;
        let startX, startY, translateX = 0, translateY = 0;

        // Evento para mostrar el popup
        thumbnails.forEach(thumbnail => {
            thumbnail.addEventListener('click', () => {
                popupImage.src = thumbnail.src; // Carga la imagen
                popup.classList.add('show'); // Muestra el popup
            });
        });

        // Evento para cerrar el popup
        closeBtn.addEventListener('click', () => {
            popup.classList.remove('show');
            resetZoom();
        });

        // Click para alternar entre zoom in y zoom out
        popupImage.addEventListener('click', () => {
            if (isZoomedIn) {
                resetZoom();
            } else {
                zoomIn();
            }
        });

        // Drag para mover la imagen mientras está ampliada
        popupImage.addEventListener('mousedown', (e) => {
            if (!isZoomedIn) return;
            isDragging = true;
            startX = e.clientX - translateX;
            startY = e.clientY - translateY;
            popupImage.style.cursor = 'grabbing';
        });

        popupImage.addEventListener('mousemove', (e) => {
            if (!isDragging) return;
            translateX = e.clientX - startX;
            translateY = e.clientY - startY;
            updateTransform();
        });

        popupImage.addEventListener('mouseup', () => {
            isDragging = false;
            popupImage.style.cursor = 'grab';
        });

        popupImage.addEventListener('mouseleave', () => {
            isDragging = false;
            popupImage.style.cursor = 'grab';
        });

        // Funciones de zoom
        function zoomIn() {
            isZoomedIn = true;
            popupImage.style.transform = `scale(2)`;
            popupImage.style.cursor = 'grab';
        }

        function resetZoom() {
            isZoomedIn = false;
            translateX = 0;
            translateY = 0;
            popupImage.style.transform = `scale(1)`;
        }

        // Actualizar posición durante el drag
        function updateTransform() {
            popupImage.style.transform = `scale(2) translate(${translateX}px, ${translateY}px)`;
        }

        function toggleDropdown(button) {
                const dropdown = button.nextElementSibling;
                if (dropdown.classList.contains("hidden")) {
                    dropdown.classList.remove("hidden");
                } else {
                    dropdown.classList.add("hidden");
                }
            }
    </script>
</body>