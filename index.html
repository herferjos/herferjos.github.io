<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Reporte de Noticias - Inteligencia Artificial</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        .image-container {
            max-width: 500px;
            max-height: 500px;
            overflow: hidden;
            border: 2px solid #ccc;
            border-radius: 10px;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
            position: relative;
            margin: 0 auto;
        }

        .image-container img {
            width: 100%;
            height: auto;
            cursor: pointer;
            object-fit: cover;
        }

        /* Popup */
        .popup-overlay {
            display: none;
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0, 0, 0, 0.8);
            justify-content: center;
            align-items: center;
            z-index: 1000;
        }

        .popup-overlay img {
            max-width: 100%;
            max-height: 100%;
            cursor: grab;
            transition: transform 0.3s;
        }

        .popup-overlay.show {
            display: flex;
        }

        /* Bot√≥n de cierre */
        .close-btn {
            position: absolute;
            top: 20px;
            right: 20px;
            background: rgba(255, 255, 255, 0.8);
            border: none;
            font-size: 18px;
            font-weight: bold;
            cursor: pointer;
            padding: 5px 10px;
            border-radius: 5px;
            z-index: 1100;
        }

        .close-btn:hover {
            background: rgba(255, 255, 255, 1);
        }
    </style>
</head>
<body class="bg-gray-50 font-sans text-gray-900">
    <header class="bg-blue-600 text-white text-center py-6">
        <h1 class="text-3xl font-bold">Reporte de Noticias: Avances en Inteligencia Artificial</h1>
    </header>

    <main class="max-w-4xl mx-auto p-6 space-y-6">
        <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Nuevos Avances en Inteligencia Artificial</h2><p class='mt-6'>Recientemente, se lanz√≥ un nuevo video analizando la inteligencia artificial en 2024. Este an√°lisis promete ofrecer insights relevantes sobre el futuro de esta tecnolog√≠a. Es parte de una serie de investigaciones y charlas sobre el impacto de la IA en nuestras vidas. Puedes acceder al video aqu√≠:</p><p class='mt-6'>Adem√°s, se se√±ala que la creaci√≥n de im√°genes y videos para probar ropa ha dejado de ser un concepto de ciencia ficci√≥n. Hoy en d√≠a, es bastante com√∫n gracias a la disponibilidad de varios modelos de c√≥digo abierto que facilitan su implementaci√≥n. Esto permite a los usuarios tener una experiencia m√°s interactiva y realista al momento de adquirir prendas. Aqu√≠ puedes ver un ejemplo de esta innovadora tecnolog√≠a:</p><video controls class="w-full rounded-lg mb-4 mt-6">
                                        <source src="https://video.twimg.com/ext_tw_video/1878514710204628993/pu/vid/avc1/1196x720/0zs66_lPtKxObzQV.mp4?tag=12" type="video/mp4">
                                        Tu navegador no soporta la reproducci√≥n de este video.
                                    </video>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="es" dir="ltr">üî• ¬°NUEVO VIDEO EN EL LAB! üî•<br><br>Si a√∫n no hab√©is tenido oportunidad de ver mi directo analizado la IA en 2024, os he preparado un resumen de 25 minutos con los momentos claves!<br><br>Ten√©is el link a continuaci√≥n üëá <a href="https://t.co/kW1MSMkfjW">pic.twitter.com/kW1MSMkfjW</a></p>&mdash; Carlos Santana (@DotCSV) <a href="https://twitter.com/DotCSV/status/1878487122023501946?ref_src=twsrc%5Etfw">January 12, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Deduplicaci√≥n y Prevenci√≥n de Filtraciones de Datos en Modelos de Lenguaje</h2><p class='mt-6'>La deduplicaci√≥n y la prevenci√≥n de filtraciones de datos son esenciales al entrenar modelos de lenguaje de gran tama√±o. Un nuevo desarrollo en este campo es SemHash, una biblioteca de deduplicaci√≥n sem√°ntica altamente eficiente.</p><p class='mt-6'>Esta herramienta utiliza embebidos Model2Vec junto con un m√©todo de b√∫squeda de similitud basado en Redes Neuronales Aproximadas, lo que permite deduplicar millones de registros en un tiempo r√©cord.</p><p class='mt-6'>Seg√∫n el √∫ltimo an√°lisis realizado por Philipp Schmid, se logr√≥ deduplicar el conjunto de datos de <a href="https://x.com/arcee_ai" class="text-blue-500 underline">@arcee_ai</a> The-Tome con un umbral de 0.98 en 150.52 segundos utilizando un chip M1. Se eliminaron 582,989 entradas, resultando en un porcentaje de duplicados del 0.33% y un 0.24% de duplicados exactos.</p><p class='mt-6'>Se deduplicaron un total de 1,169,484 entradas con el mencionado umbral.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhL2YjhX0AA-x_H.jpg'>" alt="">
                                    </div><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhKjdqZW8AA8skS.jpg'>" alt="">
                                    </div><p class='mt-6'>M√°s detalles pueden encontrarse en la cuenta de Twitter de Philipp Schmid:</p>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Deduplicating  <a href="https://twitter.com/arcee_ai?ref_src=twsrc%5Etfw">@arcee_ai</a> The-Tome dataset with threshold 0.98 and length 1752473<br>Total number of deduplicated prompts with threshold 0.98: 1169484<br>Removed 582989 prompts, with a duplicate ratio of 0.33% and 0.24% exact duplicates<br>Time taken to deduplicate: 150.52 seconds on a M1‚Ä¶ <a href="https://t.co/OcWucEDWiN">https://t.co/OcWucEDWiN</a> <a href="https://t.co/uaghWPot7t">pic.twitter.com/uaghWPot7t</a></p>&mdash; Philipp Schmid (@_philschmid) <a href="https://twitter.com/_philschmid/status/1878835058259505446?ref_src=twsrc%5Etfw">January 13, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Desarrollo de Inteligencia Artificial en Reino Unido</h2><p class='mt-6'>El Primer Ministro del Reino Unido ha publicado un Plan de Acci√≥n para las Oportunidades de Inteligencia Artificial. Este plan se enfoca en impulsar el desarrollo de la inteligencia artificial en el pa√≠s, atentos a datos, energ√≠a y empleos.</p><p class='mt-6'>Matt Clifford, quien present√≥ el plan, afirm√≥ que el gobierno se compromete a implementar todas sus recomendaciones. Este enfoque probablemente resultar√° en un crecimiento significativo de la comunidad de inteligencia artificial de c√≥digo abierto en el Reino Unido, la cual ya es altamente respetada.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhK9y-2WoAAfZoF.jpg'/>" alt="">
                                    </div>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Clear plan and love the attention to data, energy, and jobs! The UK&#39;s open-source AI community is already top notch, excited to see it bloom even more. <a href="https://t.co/Bol2akSCMG">https://t.co/Bol2akSCMG</a></p>&mdash; clem ü§ó (@ClementDelangue) <a href="https://twitter.com/ClementDelangue/status/1878815092588036606?ref_src=twsrc%5Etfw">January 13, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Reflexiones sobre el Biling√ºismo</h2><p class='mt-6'>Se comparti√≥ una reflexi√≥n sobre la experiencia de ser biling√ºe. La idea central es que ser biling√ºe no solo implica hablar dos lenguas, sino tambi√©n pensar y reflexionar en ambas.</p><p class='mt-6'>Este concepto resalta la profundidad del biling√ºismo, relevando que va m√°s all√° de la mera traducci√≥n de palabras.</p>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">I&#39;ve always felt that being bilingual isn&#39;t just about speaking two languages--it&#39;s about THINKING and muttering in whichever language feels more natural depending on the topic and context. For example, I prefer doing math in Chinese because each digit is just one syllable, which‚Ä¶ <a href="https://t.co/yD2YNscWW5">https://t.co/yD2YNscWW5</a></p>&mdash; Tiezhen WANG (@Xianbao_QIAN) <a href="https://twitter.com/Xianbao_QIAN/status/1878623350953857166?ref_src=twsrc%5Etfw">January 13, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Recursos de Aprendizaje en Machine Learning</h2><p class='mt-6'>Cuatro grandes recursos de Machine Learning para comenzar la semana:</p><p class='mt-6'><ul><li>Synthetic data and smol models in 2024</li><li>A Visual Guide to Mamba and State Space Models</li><li>Byte Latent Transformer: Patches Scale Better Than Tokens</li><li>Large Concept models: Language Modeling in a Sentence Representation Space</li></ul></p><p class='mt-6'>Para m√°s detalles, consulta el art√≠culo completo en este enlace:</p>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Four great ML resources to begin your weeküßµ<br><br>1. Synthetic data and smol models in 2024<br>2. A Visual Guide to Mamba and State Space Models<br>3. Byte Latent Transformer: Patches Scale Better Than Tokens<br>4. Large Concept models: Language Modeling in a Sentence Representation Space</p>&mdash; Omar Sanseviero (@osanseviero) <a href="https://twitter.com/osanseviero/status/1878546495126810847?ref_src=twsrc%5Etfw">January 12, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Byte Latent Transformers</h2><p class='mt-6'>Un art√≠culo interesante que explora una arquitectura de modelos de lenguaje que elimina los tokens y usa parches de bytes din√°micos en su lugar.</p><p class='mt-6'>Este enfoque permite obtener m√©tricas destacadas en comparaci√≥n con otros modelos, utilizando menos operaciones de punto flotante (FLOPs).</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhHvaIvXgAAuq4t.jpg" alt="">
                                    </div><p class='mt-6'>M√°s detalles aqu√≠:</p>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">3. Byte Latent Transformers<br><br>Interesting paper exploring a LLM architecture that removes tokens and uses dynamic byte patches instead. They obtain great metrics vs. other models, and using less FLOPs<a href="https://t.co/ZdhZu0rTe9">https://t.co/ZdhZu0rTe9</a> <a href="https://t.co/8yFPGUmWaZ">pic.twitter.com/8yFPGUmWaZ</a></p>&mdash; Omar Sanseviero (@osanseviero) <a href="https://twitter.com/osanseviero/status/1878546502374834307?ref_src=twsrc%5Etfw">January 12, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Large Concept Models</h2><p class='mt-6'>Se propone el uso de predicci√≥n de conceptos (embeddings de oraciones) en lugar de predicci√≥n de tokens.</p><p class='mt-6'>El enfoque estudiado se basa en arquitecturas de difusi√≥n y en la creaci√≥n de un espacio multiling√ºe y multimodal.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhHv9WgWwAAO2Ub.jpg" alt="">
                                    </div><p class='mt-6'>M√°s informaci√≥n disponible en:</p>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">4. Large Concept Models: Language Modeling in a Sentence Representation Space<br><br>Do concept (sentence embedding) prediction rather than token prediction. The authors explore diffusion-based architectures and a multilingual, multimodal space.<a href="https://t.co/Emf0B5DSiI">https://t.co/Emf0B5DSiI</a> <a href="https://t.co/pydbWXLvl0">pic.twitter.com/pydbWXLvl0</a></p>&mdash; Omar Sanseviero (@osanseviero) <a href="https://twitter.com/osanseviero/status/1878546505323475218?ref_src=twsrc%5Etfw">January 12, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Innovaciones en Modelos de Lenguaje</h2><p class='mt-6'><strong>VideoRAG:</strong> Un nuevo marco que mejora la Recuperaci√≥n Aumentada por Generaci√≥n (RAG) al aprovechar contenido de video como fuente de conocimiento externa. Este enfoque din√°micamente recupera videos relevantes basados en consultas, integrando su contenido visual y sonoro.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhLvhKVbsAAJbwE.jpg'>" alt="">
                                    </div><p class='mt-6'><strong>Modelos de Lenguaje Peque√±os:</strong> Un an√°lisis de aproximadamente 160 investigaciones que demuestran el potencial de los peque√±os modelos de lenguaje (SLMs). El estudio abarca SLMs de prop√≥sito general, SLMs espec√≠ficos por tarea y t√©cnicas para desarrollar estos modelos.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhLsyHvaIAAggew.jpg'>" alt="">
                                    </div><p class='mt-6'><strong>Modelo de Concepto Grande de Meta:</strong> Un an√°lisis de las potencialidades y aplicaciones de los Modelos de Concepto Grande recientemente introducidos por Meta. Esta innovaci√≥n promete ampliar las capacidades actuales de inteligencia artificial.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhLrZdhbYAAfL-7.png'>" alt="">
                                    </div><p class='mt-6'><strong>LLMQuoter:</strong> Mejora las capacidades de RAG utilizando una estrategia de "citar-primero-luego-responder". Este modelo adopta Llama-3B y se afina con LoRA sobre un subconjunto de 15,000 muestras de HotPotQA, enfoc√°ndose en identificar citas clave antes de pasarlas a modelos de razonamiento.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhLo4d7bcAA-3Q9.png'>" alt="">
                                    </div><p class='mt-6'><strong>Multiagent Finetuning:</strong> Presenta un enfoque innovador para mejorar modelos de lenguaje mediante un proceso de auto-mejora. A diferencia de los m√©todos tradicionales de afino de un solo agente, que a menudo se estancan tras unos pocos intentos, este enfoque utiliza una sociedad de modelos de lenguaje derivados.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhLlclWboAAa4Mi.jpg'>" alt="">
                                    </div><p class='mt-6'>Enlaces de referencia a informaci√≥n adicional.</p>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">VideoRAG<br><br>A framework that enhances RAG by leveraging video content as an external knowledge source.<br><br>Unlike existing RAG approaches that primarily focus on text or images, VideoRAG dynamically retrieves relevant videos based on queries and incorporates both their visual and‚Ä¶ <a href="https://t.co/FrcGxqaFtL">pic.twitter.com/FrcGxqaFtL</a></p>&mdash; elvis (@omarsar0) <a href="https://twitter.com/omarsar0/status/1878827350315659421?ref_src=twsrc%5Etfw">January 13, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div><div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Small Language Models Can Still Pack a Punch<br><br>Reviews around 160 papers demonstrating the potential of small language models (SLMs).<br><br>It focuses on general-purpose SLMs, tasks-specific SLMs, and techniques to create SLMs. <a href="https://t.co/HVbfJKQKJG">pic.twitter.com/HVbfJKQKJG</a></p>&mdash; elvis (@omarsar0) <a href="https://twitter.com/omarsar0/status/1878824342798377139?ref_src=twsrc%5Etfw">January 13, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div><div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">The Future of AI<br><br>Explores the potential and applications of Large Concept Models which was  recently introduced by Meta.<a href="https://t.co/84LpkNqXkn">https://t.co/84LpkNqXkn</a> <a href="https://t.co/PHnKofvhKe">pic.twitter.com/PHnKofvhKe</a></p>&mdash; elvis (@omarsar0) <a href="https://twitter.com/omarsar0/status/1878822820177985879?ref_src=twsrc%5Etfw">January 13, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div><div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">LLMQuoter<br><br>Enhances RAG capabilities using a &quot;quote-first-then-answer&quot; strategy.<br><br>Adopts Llama-3B and finetunes with LoRA on a 15K sample subset of HotPotQA to enhance RAG by identifying key quotes before passing them to reasoning models.<br><br>&quot;This workflow reduces cognitive‚Ä¶ <a href="https://t.co/Xap57y4ZLD">pic.twitter.com/Xap57y4ZLD</a></p>&mdash; elvis (@omarsar0) <a href="https://twitter.com/omarsar0/status/1878820053933855147?ref_src=twsrc%5Etfw">January 13, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div><div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Multiagent Finetuning<br><br>Introduces multiagent finetuning, a novel approach for improving language models through self-improvement.<br><br>Unlike traditional single-agent finetuning methods that often plateau after a few iterations, this approach uses a society of language models derived‚Ä¶ <a href="https://t.co/0ys2BBO5WY">pic.twitter.com/0ys2BBO5WY</a></p>&mdash; elvis (@omarsar0) <a href="https://twitter.com/omarsar0/status/1878816276312989821?ref_src=twsrc%5Etfw">January 13, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Modelo de Razonamiento Abierto de UC Berkeley</h2><p class='mt-6'>UC Berkeley ha presentado un nuevo modelo de razonamiento totalmente abierto llamado <strong>Sky-T1-32B-Preview</strong>.</p><p class='mt-6'>Este modelo est√° dise√±ado para tareas de razonamiento y codificaci√≥n, logrando <strong>82.4%</strong> en el conjunto de datos <em>Math500</em> y <strong>86.3%</strong> en <em>LiveCodeBench-Easy</em>.</p><p class='mt-6'>El modelo y su c√≥digo son completamente de c√≥digo abierto y se puede acceder a los datos de entrenamiento.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhMcK8SaAAEwrQN.jpg" alt="">
                                    </div>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Huge. UC Berkeley just released a $450 open-source reasoning model that matches o1.<br><br>Sky-T1-32B-Preview is a fully open-source model designed for reasoning and coding tasks. <br><br>Achieves 82.4% on Math500 and 86.3% on LiveCodeBench-Easy.<br><br>It includes training data, code, and model‚Ä¶ <a href="https://t.co/YE24jhQVSk">pic.twitter.com/YE24jhQVSk</a></p>&mdash; Lior‚ö° (@LiorOnAI) <a href="https://twitter.com/LiorOnAI/status/1878876546066506157?ref_src=twsrc%5Etfw">January 13, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Discusi√≥n sobre IA y Consumo Energ√©tico</h2><p class='mt-6'>Recientemente se ha debatido mucho sobre el consumo energ√©tico de la inteligencia artificial. Sin embargo, los comentarios suelen referirse a una estimaci√≥n antigua de 2020 sobre el consumo de energ√≠a del modelo de lenguaje GPT-3, aunque hay datos m√°s recientes disponibles.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhIB0gQWYAAJV_e.jpg" alt="">
                                    </div><p class='mt-6'>Se sugiere que es importante actualizar la discusi√≥n con cifras m√°s actuales y relevantes sobre c√≥mo estos modelos impactan en los recursos energ√©ticos.</p>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Most of the discussions around AI and energy use refer to an older 2020 estimate of GPT-3 energy consumption, but a more recent paper directly measures energy use of Llama 65B as 3-4 joules per decoded token.<br><br>So an hour of streaming Netflix is equivalent to 70-90,000 65B tokens. <a href="https://t.co/70uxCVHZcR">pic.twitter.com/70uxCVHZcR</a></p>&mdash; Ethan Mollick (@emollick) <a href="https://twitter.com/emollick/status/1878631677158998285?ref_src=twsrc%5Etfw">January 13, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Opiniones Encuentro con LKY</h2><p class='mt-6'>Un comentario humor√≠stico hace referencia a la reanimaci√≥n de Lee Kuan Yew, el fundador de Singapur. En una conversaci√≥n ficticia se menciona que para arreglar Am√©rica se necesitar√≠an diez mil millones de indios, lo que provoca sorpresa entre los personajes de esta recreaci√≥n.</p>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">&quot;We did it. We resurrected LKY. Father, tell us: what should we do to fix America?&quot;<br>&quot;Ten billion H1B Indians.&quot;<br>&quot;What? B-but‚Äî&quot;<br>&quot;Forced race mixing of neighborhoods.&quot;<br>&quot;Father, no‚Äî&quot;<br>&quot;Arrest anyone who disagrees.&quot; <a href="https://t.co/HmVlADfUTb">https://t.co/HmVlADfUTb</a> <a href="https://t.co/VzDOBU3Qvk">pic.twitter.com/VzDOBU3Qvk</a></p>&mdash; zhil (@zhil_arf) <a href="https://twitter.com/zhil_arf/status/1878657144989577615?ref_src=twsrc%5Etfw">January 13, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Impacto de Steve Jobs</h2><p class='mt-6'>Steve Jobs ha sido se√±alado como alguien que probablemente sac√≥ a cientos de millones de personas de la pobreza. Su influencia en la tecnolog√≠a ha sido clave en el desarrollo de dispositivos accesibles, lo que ha mejorado considerablemente la calidad de vida de muchas personas.</p>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Steve Jobs probably lifted hundreds of millions of people of out of poverty, tbh.</p>&mdash; Minh Nhat Nguyen (@menhguin) <a href="https://twitter.com/menhguin/status/1878578588381003884?ref_src=twsrc%5Etfw">January 12, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Uso de Smartphones en Pa√≠ses en Desarrollo</h2><p class='mt-6'>Se destaca que en los pa√≠ses en desarrollo, el uso de smartphones es considerablemente mayor que el de computadoras de escritorio. Este fen√≥meno tiene un impacto positivo que afecta los ingresos y la distribuci√≥n del internet en esas regiones.</p>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">In developing countries, smartphone usage is substantially higher than PC usage, and when u factor in the income effects of the internet ...</p>&mdash; Minh Nhat Nguyen (@menhguin) <a href="https://twitter.com/menhguin/status/1878578652708995278?ref_src=twsrc%5Etfw">January 12, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Nuevos Estudios sobre Sensibilidad al Dolor</h2><p class='mt-6'>Un nuevo modelo de aprendizaje autom√°tico est√° dise√±ado para predecir la "sensibilidad al dolor" en humanos a partir de la mayor base de datos de respuestas de fMRI disponibles. Esta investigaci√≥n ha sido aprobada por comit√©s √©ticos, lo que garantiza que el proceso experimental sea responsable.</p>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="tl" dir="ltr">forbidden Ilya scaling laws alpha <a href="https://t.co/vaIzvzLXAa">https://t.co/vaIzvzLXAa</a></p>&mdash; Minh Nhat Nguyen (@menhguin) <a href="https://twitter.com/menhguin/status/1878569780363587652?ref_src=twsrc%5Etfw">January 12, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Detecci√≥n de Seguridad en Im√°genes mediante IA</h2><p class='mt-6'>Un nuevo marco permite que los modelos de lenguaje de m√∫ltiples modalidades eval√∫en la seguridad de una imagen, eliminando la necesidad de etiquetado humano. Esto representa un avance significativo en la capacidad de la inteligencia artificial para manejar contenido visual de manera m√°s aut√≥noma.</p>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Zero-shot image safety detection, no human labeling needed.<br><br>A framework that enables MLLMs to judge image safety without human labeling, using objectified rules and debiased token probability analysis.<br><br>-----<br><br>ü§î Original Problem:<br><br>‚Üí Current image safety systems rely heavily on‚Ä¶ <a href="https://t.co/6MpzY1BbwG">pic.twitter.com/6MpzY1BbwG</a></p>&mdash; Rohan Paul (@rohanpaul_ai) <a href="https://twitter.com/rohanpaul_ai/status/1878538344663220278?ref_src=twsrc%5Etfw">January 12, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Novedades en Inteligencia Artificial</h2><p class='mt-6'>Stability AI y NVIDIA est√°n colaborando en un nuevo modelo de inteligencia artificial que permite la generaci√≥n de activos en 3D a partir de una sola imagen. Esto promete revolucionar el desarrollo de contenido en tres dimensiones.</p><p class='mt-6'>La tecnolog√≠a SANA de NVIDIA est√° licenciada bajo Apache 2.0. Este modelo de texto a imagen puede generar im√°genes de hasta 4096 por 4096 p√≠xeles. SANA-0.6B es una versi√≥n competitiva, siendo 20 veces m√°s peque√±a y m√°s de 100 veces m√°s r√°pida que otros modelos m√°s grandes. Puede operar en una GPU de 16GB y generar im√°genes de 1024 por 1024 p√≠xeles en menos de un segundo.</p><p class='mt-6'>Ultravox se presenta como un modelo de lenguaje multimodal que combina texto y audio. Puede procesar voz y producir texto en tiempo real, con un tiempo de respuesta de aproximadamente 150 milisegundos y una tasa de 60 tokens por segundo usando un modelo Llama de 8 mil millones de par√°metros.</p><p class='mt-6'>Gradio ha a√±adido soporte para agentes de Langchain, permitiendo que los desarrolladores integren esta tecnolog√≠a en sus aplicaciones de IA.</p></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Desarrollo de Aplicaciones Gradio</h2><p class='mt-6'>SANA de NVIDIA ahora puede ser desplegada usando la interfaz web de Gradio, facilitando su implementaci√≥n en hardware de gama media y alta, as√≠ como el acceso a herramientas de alta definici√≥n para la creaci√≥n de im√°genes.</p><p class='mt-6'>El framework SVFR (Face Video Restoration) es una soluci√≥n que soporta la restauraci√≥n ciega de rostros, colorizaci√≥n y otras funciones de mejora de video en un solo sistema. Esto ofrece grandes posibilidades para la edici√≥n y mejora de contenido audiovisual.</p><p class='mt-6'>Los usuarios de Gradio han destacado la facilidad de uso de estos modelos a trav√©s de interfaces limpias y hermosas, dise√±adas completamente en Python, lo que permite una experiencia de usuario fluida y √°gil.</p></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Im√°genes y Videos</h2><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhJlDvta8AAloJF.jpg" alt="">
                                    </div><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhJoJIFaEAAlZRg.jpg" alt="">
                                    </div><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhKBbDbXAAAA6Ps.jpg" alt="">
                                    </div><video controls class="w-full rounded-lg mb-4 mt-6">
                                        <source src="https://video.twimg.com/ext_tw_video/1878686573883281408/pu/vid/avc1/1024x512/lzb97HvNW2ubAhcR.mp4?tag=12" type="video/mp4">
                                        Tu navegador no soporta la reproducci√≥n de este video.
                                    </video></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Novedades sobre Veo 2</h2><p class='mt-6'>El usuario Javi L√≥pez ha compartido emocionantes experiencias con la plataforma Veo 2, destacando su incre√≠ble capacidad de generar contenido audiovisual a partir de simples indicaciones, conocidos como prompts.</p><p class='mt-6'>Seg√∫n L√≥pez, Veo 2 es una revoluci√≥n total en t√©rminos de producci√≥n de medios, permitiendo que la "calidad de producci√≥n" se genere de manera r√°pida y eficiente. La calidad de los resultados es comparada con un salto temporal al futuro en cuanto a tecnolog√≠a.</p><p class='mt-6'>En un video, Javi muestra un ejemplo impresionante de lo que se puede crear con el prompt: "Realistic 35mm film: A gorgeous woman in a sleek, form-fitting futuristic astronaut suit cautiously exploring the interior of...", mostrando la versatilidad y el impacto visual de la herramienta. M√°s informaci√≥n de la creaci√≥n se puede ver en este enlace:</p><video controls class="w-full rounded-lg mb-4 mt-6">
                                        <source src="https://video.twimg.com/ext_tw_video/1878825553714720768/pu/vid/avc1/1280x720/bHrSJI8SBVYX1S8P.mp4?tag=12" type="video/mp4">
                                        Tu navegador no soporta la reproducci√≥n de este video.
                                    </video><p class='mt-6'>Otro ejemplo de Veo 2 es un corto que presenta a un pangol√≠n surfeando sobre una ola din√°mica, lo cual fue dedicado a Carlos Santana. El clip destaca la calidad y creatividad que la plataforma puede ofrecer.</p><p class='mt-6'>Ver el video aqu√≠:</p><video controls class="w-full rounded-lg mb-4 mt-6">
                                        <source src="https://video.twimg.com/ext_tw_video/1878778963079663616/pu/vid/avc1/1280x720/WwSJvy_3d-LEhXyS.mp4?tag=12" type="video/mp4">
                                        Tu navegador no soporta la reproducci√≥n de este video.
                                    </video></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Creatividad y Futuro de la Tecnolog√≠a</h2><p class='mt-6'>L√≥pez expresa que la herramienta es extremadamente creativa y puede manejar cualquier tipo de prompt, por complicado que sea. Seg√∫n √©l, es dif√≠cil de describir sin haberlo probado, compar√°ndolo con un avance significativo en el tiempo.</p><p class='mt-6'>El mismo usuario ha mencionado que su cara estaba llena de sorpresa al acceder a Veo 2, subrayando su entusiasmo por todas las posibilidades que esta tecnolog√≠a trae consigo.</p><p class='mt-6'>A trav√©s de un video, se presenta una escena con una mujer aventurera, similar a Lara Croft, atravesando un oscuro y peligroso t√∫nel en un carro de mina, lo que representa otra muestra del potencial creativo de Veo 2. Puedes visualizar este contenido aqu√≠:</p><video controls class="w-full rounded-lg mb-4 mt-6">
                                        <source src="https://video.twimg.com/ext_tw_video/1878570307599904768/pu/vid/avc1/1280x720/NdlUlwzKsYqgYGzl.mp4?tag=12" type="video/mp4">
                                        Tu navegador no soporta la reproducci√≥n de este video.
                                    </video></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Impacto Visual y Uso de IA</h2><p class='mt-6'>El impacto visual que Veo 2 genera es notable. Los usuarios est√°n entusiasmados con lo que esta plataforma puede ofrecer, se√±alando que puede cambiar por completo nuestra manera de percibir y crear contenido visual.</p><p class='mt-6'>Un clip adicional muestra un "monstruo l√≠quido peque√±o, con estilo de rapero" realizando trucos en una patineta, lo que explica la capacidad din√°mica de generaci√≥n de la herramienta.</p><p class='mt-6'>Ver el video de esta impresionante creaci√≥n aqu√≠:</p><video controls class="w-full rounded-lg mb-4 mt-6">
                                        <source src="https://video.twimg.com/ext_tw_video/1878758832018464769/pu/vid/avc1/1280x720/l9tL2MzJsVAkXUA-.mp4?tag=12" type="video/mp4">
                                        Tu navegador no soporta la reproducci√≥n de este video.
                                    </video></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Desarrollo de Agentes Multimodales</h2><p class='mt-6'>Se ha introducido el <strong>Dria-Agent-Œ±</strong>, un modelo de lenguaje de aprendizaje profundo dise√±ado para llamar funciones en Python. Con 3 mil millones de par√°metros, este modelo se equipara con las capacidades de <strong>GPT-4o</strong>. Hay un creciente inter√©s en la creaci√≥n de <em>agentes multimodales</em> que pueden manejar diversas tipos de datos, como texto y im√°genes.</p><p class='mt-6'><img src=''></p><p class='mt-6'>Un post reciente destaca la necesidad de definir c√≥mo se deber√≠an proporcionar las im√°genes durante los procesos. Se plantean preguntas sobre las mejores pr√°cticas para la inclusi√≥n de im√°genes, ya sea al inicio o en pasos intermedios del flujo de trabajo.</p><p class='mt-6'><img src=''></p></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Nuevas Herramientas y Modelos</h2><p class='mt-6'>En el √°mbito de la tecnolog√≠a <strong>multimodal</strong>, se ha lanzado un nuevo modelo de recuperaci√≥n, <em>vdr-2b-multi-v1</em>, por parte de <strong>Llama Index</strong>. Este modelo es un 70% m√°s eficiente en el uso de tokens de imagen y ofrece un rendimiento superior en comparaci√≥n con otros modelos basados en <strong>dse-qwen2</strong>. Adem√°s, proporciona un <em>inference</em> tres veces m√°s r√°pido y utiliza menos memoria VRAM.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhKu6AtXAAAi8qG.png'>" alt="">
                                    </div><p class='mt-6'>En otras noticias, <strong>ViTPose</strong> y <strong>ViTPose++</strong> est√°n ahora disponibles en la plataforma <strong>Hugging Face</strong> Transformers, lo que facilita a los desarrolladores la implementaci√≥n de estas herramientas en sus proyectos.</p><p class='mt-6'><img src=''></p></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Apoyo a la Comunidad y Recursos</h2><p class='mt-6'>Recientemente se ha a√±adido apoyo para el idioma turco en el <strong>Cookbook</strong> de <strong>Hugging Face</strong> gracias a la contribuci√≥n de varios desarrolladores. Esto representa un paso importante hacia la inclusi√≥n de m√°s idiomas en comunidades de tecnolog√≠a.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhLo01HX0AAW6TK.jpg'>" alt="">
                                    </div><p class='mt-6'>Se ha publicado informaci√≥n adicional para aquellos interesados en colaborar y contribuir a estos proyectos. Los recursos est√°n disponibles para una mejor comprensi√≥n y interacci√≥n dentro de la comunidad.</p><p class='mt-6'><img src=''></p></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Novedades en Modelos de Lenguaje</h2><p class='mt-6'>Mistral a√∫n no ha hecho un anuncio oficial sobre su nuevo modelo. Este podr√≠a estar relacionado con una versi√≥n anterior, ya que seg√∫n m√©tricas en una publicaci√≥n del blog, su rendimiento supera al de la API DeepSeek Chat. En una evaluaci√≥n reciente, el modelo Codestral 25.01 scoring alcanz√≥ un 11% en el benchmark aider polyglot. Aqu√≠ algunos resultados comparativos:</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhMurRcXEAAhFMj.jpg'/>" alt="">
                                    </div><p class='mt-6'><ul><li>62% o1 (alto)</li><li>48% DeepSeek V3</li><li>16% Qwen 2.5 Coder 32B Instruct</li><li>11% Codestral 25.01</li><li>4% gpt-4o-mini</li></ul></p>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Kinda weird tho, Mistral hasn&#39;t put out an official announcement yet??<br><br>Maybe the new endpoint points to the old one?<br><br>As the metrics in the blogpost point to it being better than DeepSeek Chat API? <a href="https://t.co/aZ41VrZQIm">https://t.co/aZ41VrZQIm</a> <a href="https://t.co/TJHmEl0Q1u">pic.twitter.com/TJHmEl0Q1u</a></p>&mdash; Vaibhav (VB) Srivastav (@reach_vb) <a href="https://twitter.com/reach_vb/status/1878897137246986482?ref_src=twsrc%5Etfw">January 13, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Lanzamiento de Helium-1</h2><p class='mt-6'>Kyutai Labs ha presentado Helium-1, un modelo de lenguaje de 2 mil millones de par√°metros orientado a dispositivos m√≥viles y de borde, superando al modelo Qwen 2.5 de 1.5 mil millones de par√°metros. Este modelo es de c√≥digo abierto y multiling√ºe, dise√±ado para funcionar con menos de 1GB de VRAM.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhMUBecW4AANQhs.jpg'/>" alt="">
                                    </div><p class='mt-6'>El entrenamiento se realiz√≥ con 2.5 billones de tokens y ofrece un tama√±o de contexto de 4096. Es comparable o mejor que otros modelos como Owen 1.5B, Gemma 2B y Llama 3B.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhMNetGWoAATXbO.jpg'/>" alt="">
                                    </div>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Base models are perfect for vibe-checks - 5 lines is all you need! üëë <a href="https://t.co/D5CxUQbsbO">https://t.co/D5CxUQbsbO</a> <a href="https://t.co/MfzTSL8xgd">pic.twitter.com/MfzTSL8xgd</a></p>&mdash; Vaibhav (VB) Srivastav (@reach_vb) <a href="https://twitter.com/reach_vb/status/1878867613134336040?ref_src=twsrc%5Etfw">January 13, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Tendencias de la AI en 2025</h2><p class='mt-6'>El mes de enero de 2025 exhibe importantes avances en el √°mbito de la inteligencia artificial, destacando el lanzamiento de productos de laboratorios abiertos, a diferencia de los laboratorios cerrados que a√∫n no han hecho anuncios significativos. Hasta ahora, se han lanzado:</p><p class='mt-6'><ul><li>OpenBMB con Eurus 2 de 7B</li><li>Nvidia Cosmos</li><li>Moondream 2</li></ul></p><p class='mt-6'>Esta informaci√≥n resalta el dinamismo del sector abierto en contrasto con el silencio de grandes nombres como Anthropic, OpenAI y Gemini.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhHy-5SWAAAd_QM.jpg'/>" alt="">
                                    </div><video controls class="w-full rounded-lg mb-4 mt-6">
                                        <source src="https://video.twimg.com/ext_tw_video/1878547975821012992/pu/vid/avc1/1112x720/wSEqoRqQc5qBtd1J.mp4?tag=12'/>" type="video/mp4">
                                        Tu navegador no soporta la reproducci√≥n de este video.
                                    </video>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">January 2025 is shaping up to be quite an OPEN MONTH so far üí• <a href="https://t.co/o6g8honXqU">https://t.co/o6g8honXqU</a> <a href="https://t.co/AJzMLbyWN2">pic.twitter.com/AJzMLbyWN2</a></p>&mdash; Vaibhav (VB) Srivastav (@reach_vb) <a href="https://twitter.com/reach_vb/status/1878549785763828220?ref_src=twsrc%5Etfw">January 12, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Opiniones sobre el futuro</h2><p class='mt-6'>Un usuario expres√≥ su opini√≥n sobre un evento previsto para el a√±o 2025, consider√°ndolo un poco loco. Esta reflexi√≥n invita a analizar c√≥mo la percepci√≥n del futuro puede parecer extrema o inusual en ciertos contextos.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhMdUflWEAA2Rgs.jpg" alt="">
                                    </div><p class='mt-6'>El comentario genera una conversaci√≥n acerca de lo que se espera para el a√±o 2025 y c√≥mo estas expectativas pueden ser vistas desde diferentes perspectivas.</p>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">in 2025 this is a bit crazy imo <a href="https://t.co/cSpFmRLf5w">pic.twitter.com/cSpFmRLf5w</a></p>&mdash; Julien Chaumond (@julien_c) <a href="https://twitter.com/julien_c/status/1878877780118745175?ref_src=twsrc%5Etfw">January 13, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Desarrollo de Inteligencia Artificial</h2><p class='mt-6'>La comunidad de c√≥digo abierto est√° experimentando un crecimiento notable en las tecnolog√≠as de generaci√≥n de voz. Un tuit destaca el avance de las herramientas de s√≠ntesis de texto a voz (TTS, por sus siglas en ingl√©s) que ofrecen inferencia r√°pida. Se invita a los desarrolladores a compartir sus proyectos relacionados con estas tecnolog√≠as. Este avance promete revolucionar la forma en que interactuamos con las m√°quinas y permite la creaci√≥n de aplicaciones innovadoras.</p><p class='mt-6'><img src=''></p><p class='mt-6'>Un nuevo art√≠culo ha sido publicado en el blog de Hugging Face, donde se discute la importancia de las dimensiones de los tensores y su propagaci√≥n en modelos de aprendizaje autom√°tico. Este an√°lisis es fundamental para comprender c√≥mo funcionan y se optimizan los algoritmos de IA en tareas complejas.</p><p class='mt-6'><img src=''></p><p class='mt-6'>Visita los enlaces a continuaci√≥n para m√°s informaci√≥n.</p></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Lanzamiento de SetFit v1.1.1</h2><p class='mt-6'>El software SetFit se ha actualizado a la versi√≥n 1.1.1. Este modelo permite el ajuste de modelos de clasificaci√≥n muy eficientes en CPU y GPU, utilizando el modelo de incrustaci√≥n ModernBERT de Nomic AI.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhK43CaXsAAXUjD.jpg'>" alt="">
                                    </div><p class='mt-6'>Esta actualizaci√≥n es especialmente √∫til para facilitar el entrenamiento de peque√±os clasificadores, que son valiosos para tareas de enrutamiento en modelos de lenguaje grande. Estos clasificadores son sencillos de entrenar y no requieren grandes vol√∫menes de datos.</p><p class='mt-6'>Detalles sobre esta versi√≥n est√°n disponibles en el video publicado.</p>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">I&#39;ve just published SetFit v1.1.1, allowing finetuning extremely efficient classification models on CPU &amp; GPU based on Nomic AI their ModernBERT embedding model. <br><br>Details in üßµ <a href="https://t.co/40a9Qg0cwk">pic.twitter.com/40a9Qg0cwk</a></p>&mdash; tomaarsen (@tomaarsen) <a href="https://twitter.com/tomaarsen/status/1878767886204096914?ref_src=twsrc%5Etfw">January 13, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Nuevas funcionalidades y compatibilidad</h2><p class='mt-6'>La nueva versi√≥n incluye compatibilidad con las versiones de Transformers v4.45.2 y superiores. Usar la versi√≥n 4.48.0 tambi√©n agrega soporte para la arquitectura ModernBERT.</p><p class='mt-6'>Adicionalmente, se ha corregido un error donde la opci√≥n `report_to="none"` no era aplicada correctamente en los argumentos de entrenamiento. Ahora, esta opci√≥n deber√≠a deshabilitar correctamente las llamadas autom√°ticas si as√≠ se desea.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhK5JcsWYAA-OTT.png'>" alt="">
                                    </div><p class='mt-6'>Puedes revisar el script de entrenamiento con ModernBERT visitando las notas de la versi√≥n.</p>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Updates:<br>- Compatibility with Transformers v4.45.2+ is added. Using v4.48.0 adds ModernBERT architecture support as well!<br>- Prevent `report_to=&quot;none&quot;` from being ignored in the TrainingArguments. This should now correctly disable automatic callbacks if you want.<br><br>üßµ <a href="https://t.co/0sdoH4EV9d">pic.twitter.com/0sdoH4EV9d</a></p>&mdash; tomaarsen (@tomaarsen) <a href="https://twitter.com/tomaarsen/status/1878767889785979109?ref_src=twsrc%5Etfw">January 13, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Contenido adicional de YouTube</h2><p class='mt-6'>Niels Rogge ha compartido su intenci√≥n de crear m√°s contenido en YouTube en 2025. En su √∫ltimo video, habla sobre todas las nuevas caracter√≠sticas en Hugging Face.</p><p class='mt-6'>Esto es un punto de inter√©s para quienes buscan actualizaciones sobre herramientas de inteligencia artificial y modelos de lenguaje.</p><p class='mt-6'>El tweet se puede consultar en:</p>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">One of my goals in 2025 is making more <a href="https://twitter.com/YouTube?ref_src=twsrc%5Etfw">@YouTube</a> content<br><br>In today&#39;s video I go over ALL of the new features in <a href="https://twitter.com/huggingface?ref_src=twsrc%5Etfw">@huggingface</a> Transformers v4.48: ModernBERT, ColPali, ViTPose, and more!<br><br>I also accidentally explain how a Transformer works to make you understand ModernBERT :) <a href="https://t.co/eYY7mbVWlr">pic.twitter.com/eYY7mbVWlr</a></p>&mdash; Niels Rogge (@NielsRogge) <a href="https://twitter.com/NielsRogge/status/1878115664654635490?ref_src=twsrc%5Etfw">January 11, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Sorpresa con el panel de conocimiento de Google</h2><p class='mt-6'>Un usuario comparti√≥ su grata sorpresa al encontrar su nombre en el panel de conocimiento de Google tras realizar una b√∫squeda aleatoria.</p><p class='mt-6'>El usuario hab√≠a expresado su deseo de tener presencia en este panel hace algunos meses y se sorprendi√≥ por la rapidez con la que fue reconocida su existencia.</p><p class='mt-6'>Sin embargo, not√≥ que su nombre estaba mal escrito en escritura cir√≠lica serbia y planea corregirlo una vez que Google confirme la informaci√≥n.</p><p class='mt-6'>Aqu√≠ se puede ver la imagen del panel:</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhMLnxxXYAEbMnE.png" alt="">
                                    </div><p class='mt-6'>M√°s detalles en el tweet original:</p>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">just got pleasantly surprised by Google&#39;s knowledge panel - I didn&#39;t expect it to come so quickly, as it become one of my wishes just few months ago!<br><br>i randomely searched for my name today and saw it!<br><br>they did mess up my name in Serbian Cyrillic but I&#39;ll fix it once they verify‚Ä¶ <a href="https://t.co/EeLeX1LapY">pic.twitter.com/EeLeX1LapY</a></p>&mdash; Aleksa Gordiƒá üçøü§ñ (@gordic_aleksa) <a href="https://twitter.com/gordic_aleksa/status/1878858476572594594?ref_src=twsrc%5Etfw">January 13, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Desaf√≠os y Propuestas en la Educaci√≥n con Inteligencia Artificial</h2><p class='mt-6'>Algunos educadores consideran que prohibir el uso de la inteligencia artificial en clases puede ser necesario para que los estudiantes desarrollen habilidades fundamentales. Este proceso recuerda los debates en torno al uso de calculadoras en matem√°ticas, donde la prohibici√≥n persiste en ciertas etapas de aprendizaje.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/Ek-08K7W0AEZodn.jpg">" alt="">
                                    </div><p class='mt-6'>El compromiso activo es esencial para el aprendizaje; sin embargo, muchos estudiantes encuentran este proceso inc√≥modo. La percepci√≥n de que se aprende menos mientras se trabaja duro puede llevar a confusiones. Algunos educadores, como Ethan Mollick, aclaran que se debe persuadir a los estudiantes sobre los beneficios del esfuerzo.</p><p class='mt-6'>Mollick tambi√©n opina que las pol√≠ticas sobre el uso de la inteligencia artificial deben adaptarse a las necesidades del aula, requiriendo trabajos y m√©todos de evaluaci√≥n claros si se permite el uso de esta tecnolog√≠a.</p>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2">https://x.com/emollick/status/1878825523788574880">Referencia</a></div><div class="hidden mt-2">https://x.com/emollick/status/1878822589285757049">Referencia</a></div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Impacto Energ√©tico y Eficiencia de AI</h2><p class='mt-6'>Las discusiones sobre el impacto energ√©tico de la inteligencia artificial a menudo se basan en estimaciones antiguas. Un estudio reciente midi√≥ el consumo energ√©tico del modelo Llama 65B y encontr√≥ que consume entre 3 y 4 julios por token, lo que contrasta con estimaciones anteriores.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhI9hVyWYAAz14Z.jpg">" alt="">
                                    </div><p class='mt-6'>Un an√°lisis comparativo muestra que ver una hora de Netflix equivale a consumir entre 70,000 y 90,000 tokens de Llama 65B, lo cual es un dato impactante para considerar el impacto ambiental de las IA.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhI9ipvWcAA79sV.png">" alt="">
                                    </div><p class='mt-6'>Por otro lado, se especula que los avances en eficiencia podr√≠an haber mejorado el rendimiento energ√©tico en modelos m√°s recientes, como el Llama 3.3 70B, reduciendo su consumo a 0.4 julios por token.</p>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2">https://x.com/emollick/status/1878693307360137649">Referencia</a></div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Interacciones con AI: Creatividad y Comportamientos</h2><p class='mt-6'>Se observa frustraci√≥n en algunos usuarios respecto a la calidad de las respuestas generadas por sistemas de inteligencia artificial. Una cr√≠tica espec√≠fica se dirige a comentarios poco sustanciales en respuesta a posturas pensadas, sugiriendo que los usuarios pueden elevar la calidad de sus interacciones.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhJLmvoXcAMgS7b.jpg">" alt="">
                                    </div><p class='mt-6'>Mientras tanto, un experimento creativo implic√≥ usar un modelo de inteligencia artificial llamado Claude para transformar el poema 'La Dama de Shalott' en clips visuales. La experimentaci√≥n, aunque imperfecta, abri√≥ discusiones sobre el potencial creativo de estas tecnolog√≠as.</p><video controls class="w-full rounded-lg mb-4 mt-6">
                                        <source src="https://video.twimg.com/ext_tw_video/1878602293039243264/pu/vid/avc1/1280x720/ESCLBGPhlUPMYykK.mp4?tag=12"></video>" type="video/mp4">
                                        Tu navegador no soporta la reproducci√≥n de este video.
                                    </video>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2">https://x.com/emollick/status/1878603578274959556">Referencia</a></div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Interacciones en Redes Sociales</h2><p class='mt-6'>En un reciente tweet, el usuario <a href="https://x.com/hammer_mt" class="text-blue-500 underline">@hammer_mt</a> destac√≥ el cambio de enfoque en el pensamiento de una perspectiva secuencial a una m√°s centrada en las personas. Esta aclaraci√≥n fue compartida por Dan Shipper, quien tambi√©n recomend√≥ leer m√°s sobre el tema en el hilo de <a href="https://x.com/hammer_mt" class="text-blue-500 underline">@hammer_mt</a>.</p><p class='mt-6'>El usuario <a href="https://x.com/hammer_mt" class="text-blue-500 underline">@hammer_mt</a> tambi√©n se refiri√≥ a un video de <a href="https://x.com/syntheticusers" class="text-blue-500 underline">@syntheticusers</a>, subrayando que exist√≠a conocimiento previo sobre el tema discutido. El comentario resalt√≥ el trabajo del propio <a href="https://x.com/hammer_mt" class="text-blue-500 underline">@hammer_mt</a> como valioso y bien recibido.</p></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Opiniones sobre Controversias e Investigaciones</h2><p class='mt-6'>Un tuit de Sam Ashworth-Hayes menciona la peculiaridad de los obst√°culos enfrentados por quienes investigaron el caso de abuso en Rotherham. Los testimonios revelaron que hubo registros que desaparecieron de edificios cerrados, as√≠ como declaraciones amenazantes por parte de la polic√≠a, indicando una falta de transparencia en la investigaci√≥n.</p><p class='mt-6'>He aqu√≠ algunas im√°genes que ilustran esta problem√°tica:</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhLaYe5WEAAx1kN.jpg" alt="">
                                    </div><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhLaYg4XUAAXG5A.jpg" alt="">
                                    </div><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhLaY7DWUAAFu-k.jpg" alt="">
                                    </div></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Cambio Clim√°tico y Emisiones de Carbono</h2><p class='mt-6'>Roope Rainisto public√≥ en Twitter que, si alguien cree en el cambio clim√°tico, deber√≠a considerar no contratar trabajadores humanos. Su an√°lisis muestra que los sistemas de inteligencia artificial emiten entre 130 y 1500 veces menos di√≥xido de carbono equivalente por p√°gina de texto en comparaci√≥n con los escritores humanos, y entre 310 y 2900 veces menos por imagen generada, en comparaci√≥n con ilustradores humanos.</p><p class='mt-6'>Este enfoque en IA se presenta como un m√©todo m√°s sostenible en t√©rminos de emisiones de carbono.</p></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Im√°genes y Gr√°ficos</h2><p class='mt-6'>Un gr√°fico relevante se comparte en la conversaci√≥n sobre la necesidad de un blueprint, aportando una perspectiva visual sobre el tema que se discute.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhIeDiJXgAACvS-.jpg" alt="">
                                    </div></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Innovaciones en Modelos de Lenguaje</h2><p class='mt-6'>Un usuario en Twitter ha compartido una innovadora ejecuci√≥n de un modelo de lenguaje en una consola Xbox 360. Esta consola cuenta con un procesador Xenon de 3.2GHz y 512MB de RAM unificada. Est√° basado en la implementaci√≥n del modelo llama2, lo cual demuestra la capacidad de realizar tareas complejas en hardware menos potente.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhLl7D2XEAAVprC.jpg" alt="">
                                    </div><p class='mt-6'>Esta ejecuci√≥n es un claro ejemplo de c√≥mo los modelos de lenguaje pueden optimizarse para funcionar en dispositivos que no son t√≠picamente considerados para este prop√≥sito. Esto abre puertas a nuevas aplicaciones de inteligencia artificial en hardware cotidiano.</p>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">LLM running on Xbox 360 <br><br>With Xenon CPU (3.2GHz PowerPC w/ 3 cores) and 512MB unified RAM. Based on <a href="https://twitter.com/karpathy?ref_src=twsrc%5Etfw">@karpathy</a>&#39;sü©∑llama2.c, ported to run on Microsoft&#39;s powerful console from 2005. Pure C implementation optimized for PowerPC architecture and Xbox memory management. <br><br>Inspired by‚Ä¶ <a href="https://t.co/e9oMLaWIyi">pic.twitter.com/e9oMLaWIyi</a></p>&mdash; Andrei David (@AndreiDavid) <a href="https://twitter.com/AndreiDavid/status/1877792408991121842?ref_src=twsrc%5Etfw">January 10, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Mejoras en Eficiencia de Modelos</h2><p class='mt-6'>MinishLab ha presentado una nueva t√©cnica denominada Semhash que acelera y optimiza la generaci√≥n de embeddings para deduplicaci√≥n sem√°ntica. Este avance permite obtener mejores modelos al filtrar conjuntos de datos, lo que a su vez reduce el tiempo de entrenamiento y la necesidad de recursos computacionales.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhLM0bzXoAAD2GP.jpg" alt="">
                                    </div><p class='mt-6'>Los desarrolladores interesados pueden acceder al repositorio que alberga esta innovadora t√©cnica, que promete revolucionar los m√©todos de entrenamiento de modelos de lenguaje. La eficiencia es clave en el desarrollo actual de inteligencia artificial, y herramientas como Semhash son esenciales.</p>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">MinishLab made another great effort to make embeddings work quicker, cleaner and leaner with Semhash for semantic deduplication.<br><br>You can get better models by filtering datasets, while also reducing training time and required compute.<br><br>Repo: <a href="https://t.co/c56jjeEAal">https://t.co/c56jjeEAal</a> <a href="https://t.co/HhBCr8KEbL">pic.twitter.com/HhBCr8KEbL</a></p>&mdash; David Berenstein (@davidberenstei) <a href="https://twitter.com/davidberenstei/status/1878816801024262154?ref_src=twsrc%5Etfw">January 13, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Creaci√≥n de Conjuntos de Datos Cr√≠ticos</h2><p class='mt-6'>El proyecto SCRIT, junto con el concepto de Critico Contrastivo, se centra en la creaci√≥n de conjuntos de datos cr√≠ticos al agregar razonamiento sint√©tico para dirigir el uso de una respuesta correcta conocida. Esta metodolog√≠a ofrece voces disidentes en el an√°lisis de respuestas y ayuda a profundizar en los modelos de lenguaje.</p><p class='mt-6'>Esta propuesta es interesante para aquellos que buscan mejorar la calidad de la interacci√≥n entre humanos y modelos de inteligencia artificial. La clave est√° en c√≥mo se utilizan los datos sint√©ticos para enriquecer la comprensi√≥n y la cr√≠tica.</p>
                    <div class="mt-6">
                        <button onclick="toggleDropdown(this)" class="bg-blue-500 text-white px-4 py-2 rounded-lg">
                            Ver fuente
                        </button>
                        <div class="hidden mt-2"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">SCRIT and Contrastive Critic: creating a good critique dataset by adding synthetic reasoning towards using a known correct answer.<br><br>One interesting insight but you can always dive deeper.<br><br>Paper: <a href="https://t.co/kypWCyEnhj">https://t.co/kypWCyEnhj</a> <a href="https://t.co/IwSj54MaQE">pic.twitter.com/IwSj54MaQE</a></p>&mdash; David Berenstein (@davidberenstei) <a href="https://twitter.com/davidberenstei/status/1878789198624272827?ref_src=twsrc%5Etfw">January 13, 2025</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>
                    </div>
                </section>
                <section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Avances en Modelos de Lenguaje y Tecnolog√≠a</h2><p class='mt-6'>Recientemente, se present√≥ una demostraci√≥n de uso de modelos de lenguaje abierto, donde se utilizan tres modelos diferentes. Este avance podr√≠a ser crucial para el desarrollo de aplicaciones m√°s complejas y vers√°tiles en inteligencia artificial.</p><p class='mt-6'>Descubre m√°s sobre el futuro de la inteligencia artificial y las aplicaciones de los Modelos de Concepto Grande presentados por Meta.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhJ_-ypagAAUvy7.jpg" alt="">
                                    </div><p class='mt-6'>La implementaci√≥n de agentes de razonamiento y actuaci√≥n transformar√° c√≥mo abordamos tareas complejas en inteligencia artificial. Esta metodolog√≠a permite a los agentes crear tutoriales completos con un solo comando, demostrando las capacidades avanzadas de los modelos actuales.</p><div class="image-container">
                                        <img id="thumbnail" src="https://pbs.twimg.com/media/GhJSVHabYAERYCb.jpg" alt="">
                                    </div></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Innovaciones y Nuevas Herramientas</h2><p class='mt-6'>SemHash es una nueva herramienta para la deduplicaci√≥n de textos sem√°nticos, fundamental en la formaci√≥n de modelos de lenguaje, con un enfoque en prevenir la fuga de datos y optimizar el entrenamiento.</p><p class='mt-6'>NVIDIA ha anunciado su apoyo p√∫blico a la administraci√≥n de Trump y ha criticado la administraci√≥n de Biden respecto al impacto en la inteligencia artificial.</p><p class='mt-6'>Quantalogic lanz√≥ una nueva versi√≥n que incluye mejoras como la inyecci√≥n de propiedades de herramienta en tiempo de ejecuci√≥n y soporte para plantillas de Jinja2, ampliando sus funcionalidades para desarrolladores.</p></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Impacto de la Inteligencia Artificial en el Entorno Actual</h2><p class='mt-6'>El uso de la tecnolog√≠a eBPF para capturar el tr√°fico local muestra un enfoque innovador hacia la seguridad de procesos en sistemas operativos, destacando su importancia en el desarrollo de soluciones que abordan la ciberseguridad.</p><p class='mt-6'>El inter√©s por la inteligencia artificial ha llevado a la comunidad a preguntarse sobre las posibilidades de construir aplicaciones con tecnolog√≠as de s√≠ntesis de voz que ahora son de c√≥digo abierto y con baja latencia.</p></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">¬øPor qu√© a√∫n no pueden pensar como humanos?</h2><p class='mt-6'>En un an√°lisis reciente, se estudi√≥ la capacidad de razonamiento de modelos de lenguaje m√°s peque√±os como Llama y Phi-4. Se usa una t√©cnica que se llama "Chain of Thought Supervised Fine-tuning" (CoT-SFT), que ense√±a a los modelos a razonar a trav√©s de ejemplos paso a paso.</p><p class='mt-6'>Este m√©todo muestra mejoras, pero no es una soluci√≥n definitiva. A pesar de que los modelos pueden aparentar razonamiento, a menudo, se apoyan en sus sesgos internos. Se requiere un cambio m√°s profundo en su forma de decidir lo que dir√°n a continuaci√≥n para mejorar su capacidad de razonamiento real.</p></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">El problema de las primeras impresiones</h2><p class='mt-6'>Cuando se le hace una pregunta de opci√≥n m√∫ltiple a un modelo de inteligencia artificial, a menudo se aferra a la primera respuesta que cree que es correcta. Esta respuesta suele ser defendida con un razonamiento que parece l√≥gico, pero que est√° basado en un error inicial.</p><p class='mt-6'>Incluso si el modelo tiene la respuesta correcta en alg√∫n lugar de su red de par√°metros, puede no tener acceso a ella f√°cilmente, optando por lo que le viene a la mente primero.</p></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">La soluci√≥n: Considerar m√∫ltiples perspectivas</h2><p class='mt-6'>Para resolver este problema, se propone aumentar el tiempo de pensamiento y considerar m√∫ltiples perspectivas antes de llegar a una conclusi√≥n. En un video, se presenta una versi√≥n mejorada del modelo Llama, conocida como Llama 3.2 MedIT 3B o1.</p><p class='mt-6'>Este modelo innovador incluye m√∫ltiples 'thinkers' que trabajan simult√°neamente en el problema. Esto se traduce en un aumento en el 'Test-Time Compute' (TTC), lo que permite al modelo realizar un mayor esfuerzo durante la evaluaci√≥n.</p><p class='mt-6'>Los 'thinkers' no solo trabajan de manera independiente, sino que comparan sus creencias internas sobre la respuesta correcta, facilitando as√≠ una mejor toma de decisiones.</p></section><section class="bg-white shadow-md rounded-lg p-6">
                    <h2 class="text-2xl font-semibold mb-4">Un ejemplo pr√°ctico: Contando las 'R'</h2><p class='mt-6'>Un ejemplo pr√°ctico consiste en pedir al modelo que cuente las letras 'R' en la palabra 'strawberry', y luego en 'rover'. Este ejercicio Challenge busca que el modelo sea preciso y no se apresure a concluir.</p><p class='mt-6'>El objetivo es ense√±ar a la inteligencia artificial a considerar m√∫ltiples l√≠neas de razonamiento antes de elegir la mejor opci√≥n.</p></section>
    </main>

    <footer class="bg-blue-600 text-white text-center py-4">
        <p>&copy; 2025 Todos los derechos reservados. Reporte de Noticias - Inteligencia Artificial</p>
    </footer>

    <div id="popup" class="popup-overlay">
        <button class="close-btn" id="close-btn">X</button>
        <img id="popup-image" src="" alt="Imagen ampliada">
    </div>

    <script>
        // Elementos del DOM
        const thumbnails = document.querySelectorAll('.image-container img');
        const popup = document.getElementById('popup');
        const popupImage = document.getElementById('popup-image');
        const closeBtn = document.getElementById('close-btn');

        // Variables para el zoom
        let isZoomedIn = false;
        let isDragging = false;
        let startX, startY, translateX = 0, translateY = 0;

        // Evento para mostrar el popup
        thumbnails.forEach(thumbnail => {
            thumbnail.addEventListener('click', () => {
                popupImage.src = thumbnail.src; // Carga la imagen
                popup.classList.add('show'); // Muestra el popup
            });
        });

        // Evento para cerrar el popup
        closeBtn.addEventListener('click', () => {
            popup.classList.remove('show');
            resetZoom();
        });

        // Click para alternar entre zoom in y zoom out
        popupImage.addEventListener('click', () => {
            if (isZoomedIn) {
                resetZoom();
            } else {
                zoomIn();
            }
        });

        // Drag para mover la imagen mientras est√° ampliada
        popupImage.addEventListener('mousedown', (e) => {
            if (!isZoomedIn) return;
            isDragging = true;
            startX = e.clientX - translateX;
            startY = e.clientY - translateY;
            popupImage.style.cursor = 'grabbing';
        });

        popupImage.addEventListener('mousemove', (e) => {
            if (!isDragging) return;
            translateX = e.clientX - startX;
            translateY = e.clientY - startY;
            updateTransform();
        });

        popupImage.addEventListener('mouseup', () => {
            isDragging = false;
            popupImage.style.cursor = 'grab';
        });

        popupImage.addEventListener('mouseleave', () => {
            isDragging = false;
            popupImage.style.cursor = 'grab';
        });

        // Funciones de zoom
        function zoomIn() {
            isZoomedIn = true;
            popupImage.style.transform = `scale(2)`;
            popupImage.style.cursor = 'grab';
        }

        function resetZoom() {
            isZoomedIn = false;
            translateX = 0;
            translateY = 0;
            popupImage.style.transform = `scale(1)`;
        }

        // Actualizar posici√≥n durante el drag
        function updateTransform() {
            popupImage.style.transform = `scale(2) translate(${translateX}px, ${translateY}px)`;
        }

        function toggleDropdown(button) {
                const dropdown = button.nextElementSibling;
                if (dropdown.classList.contains("hidden")) {
                    dropdown.classList.remove("hidden");
                } else {
                    dropdown.classList.add("hidden");
                }
            }
    </script>
</body>